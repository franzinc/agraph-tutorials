{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe40e060-09ee-4707-8656-28b16fc6dea4",
   "metadata": {},
   "source": [
    "# AllegroGraph ETL\n",
    "\n",
    "If you are connecting in a regular jupyter notebook and have activated our `ag-tutorial` environment then you do not need to run the following cell to install `agraph-python` and `pandas`. However, if you are in a **Google Colab** please run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c33c2-2f81-4f40-8c3d-60dc46aa425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agraph-python pycurl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46239e8d-dbfe-4e44-8272-7d3230a71ad1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We start by setting the environment variables based on your server installation.\n",
    "If you are connecting on a cloud server, you do not need to change `AGRAPH_PORT` or `AGRAPH_USER`, but you do need to change `AGRAPH_HOST` and `AGRAPH_PASSWORD` to fit your server. We have left some variables in place as an example of what to look for, but they need to be replaced with your values.\n",
    "If you are connecting to a local installation the host will most likely be `localhost` and whatever port you installed AllegroGraph on (standard is `10035`). Then your `AGRAPH_USER` and `AGRAPH_PASSWORD` need to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2792d980-2042-4615-8d2a-572987959bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['AGRAPH_HOST'] = 'https://ag197y8xsj2epl2e.allegrograph.cloud' #add your AllegroGraph Cloud url here (starting with https, copy till the end of allegrograph.cloud)\n",
    "os.environ['AGRAPH_PORT'] = '443' #Agraph is listening at port 443, you do not need to change this if you are connected to a cloud server\n",
    "os.environ['AGRAPH_USER'] = 'admin' #your username should be 'admin', you do not need to change this if you are connected to a cloud server\n",
    "os.environ['AGRAPH_PASSWORD'] = 'GrMEKDvQFaN2bkrHJeiCbv' #Add your password here as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc28ca74-9856-4bab-b9e5-a1813330858c",
   "metadata": {},
   "source": [
    "Then we import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72cc27f5-1e48-4347-9dcf-7ca55b2d62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "from franz.openrdf.query.query import QueryLanguage\n",
    "from franz.openrdf.vocabulary import RDF, RDFS\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873be8dc-cdcd-4dca-b434-69df22a84cef",
   "metadata": {},
   "source": [
    "Create a new respository (or we clear it if it already exists) and set the namespaces both in the local python environment and on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee11e0a9-22d5-4040-8882-4f120709deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = ag_connect('agraph-etl', clear=True)\n",
    "\n",
    "f = conn.namespace('http://franz.com/example-etl/') #sets the namespace in the local python environment\n",
    "conn.setNamespace('f', 'http://franz.com/example-etl') #sets the namespace on the server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8cadf-fe19-44ea-bef3-ee3fa40b77d7",
   "metadata": {},
   "source": [
    "A quick utility class to most efficiently add large amounts of triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a41543c0-aacd-4450-bf84-7ad90af44596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BufferTriples:\n",
    "    def __init__(self, conn, max_size=10000):\n",
    "        self.conn = conn\n",
    "        self.buffer_triples = []\n",
    "        self.max_size = max_size\n",
    "        \n",
    "    def add_triple_to_buffer(self, triple):\n",
    "        if len(self.buffer_triples) < self.max_size:\n",
    "            self.buffer_triples.append(triple)\n",
    "        else:\n",
    "            self.conn.addTriples(self.buffer_triples)\n",
    "            self.buffer_triples = [triple]\n",
    "            \n",
    "    def flush_triples(self):\n",
    "        self.conn.addTriples(self.buffer_triples)\n",
    "        self.buffer_triples=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4818a-b4f3-4565-aba9-8c8317d6e59e",
   "metadata": {},
   "source": [
    "# ETL on CSV/XLSX Files and/or SQL Tables\n",
    "\n",
    "Here we will import some CSV files and read them into Pandas dataframes and then convert them to triples. Even though these dataframes will be very small, this same method would work for much larger datasets as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a5bcce5-dcdf-4933-a7aa-fd010ef76efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#beings_df = pd.read_csv('data/beings.csv')\n",
    "beings_df = pd.read_csv('https://raw.githubusercontent.com/franzinc/agraph-tutorials/master/data/beings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9aff1a1-d97d-4687-80e7-41771c346c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Aragorn</td>\n",
       "      <td>87</td>\n",
       "      <td>Dúnedain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Frodo</td>\n",
       "      <td>50</td>\n",
       "      <td>Hobbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Legolas</td>\n",
       "      <td>2931</td>\n",
       "      <td>Elf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gimli</td>\n",
       "      <td>140</td>\n",
       "      <td>Dwarf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gandalf</td>\n",
       "      <td>2000</td>\n",
       "      <td>Wizard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     name   age      race\n",
       "0   1  Aragorn    87  Dúnedain\n",
       "1   2    Frodo    50    Hobbit\n",
       "2   3  Legolas  2931       Elf\n",
       "3   4    Gimli   140     Dwarf\n",
       "4   5  Gandalf  2000    Wizard"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e690bb-5bfc-492d-aec7-d121b4a7e033",
   "metadata": {},
   "source": [
    "First we create a buffer that will allow us to add triples to the server whenever we so desire. \n",
    "\n",
    "Then we loop through the dataframe and create a unique URI based on the being's `id` column. Then we attach all other metadata to that newly created URI by adding triples to the buffer. At the end of this process we \"flush\" the triples, meaning we add the triples in the buffer to the server. (Meaning the buffer is now empty, but still exists in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8627af7-fe90-41e7-b8c1-8cfab8f7df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = BufferTriples(conn)\n",
    "for index, row in beings_df.iterrows():\n",
    "    being_uri = conn.createURI(f\"http://franz.com/example-being/{str(row['id'])}\")\n",
    "    buffer.add_triple_to_buffer((being_uri, RDF.TYPE, f.Being))\n",
    "    buffer.add_triple_to_buffer((being_uri, f.name, row['name']))\n",
    "    buffer.add_triple_to_buffer((being_uri, RDFS.LABEL, row['name']))\n",
    "    buffer.add_triple_to_buffer((being_uri, f.age, row['age']))\n",
    "    buffer.add_triple_to_buffer((being_uri, f.race, row['race']))\n",
    "\n",
    "buffer.flush_triples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90328d93-4289-446d-80e5-ea3a70a9087b",
   "metadata": {},
   "source": [
    "We can now examine the data in Gruff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94a41c-7528-4157-b7a2-812f3a5a2c3e",
   "metadata": {},
   "source": [
    "![beings-etl](images/beings-etl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4431234-f781-47b5-8711-229bc8cdf6e3",
   "metadata": {},
   "source": [
    "Next, we import a CSV file consisting of different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec07314-3e30-42be-b60b-bb9275f87734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#languages_df = pd.read_csv('data/beings-languages.csv')\n",
    "languages_df = pd.read_csv('https://raw.githubusercontent.com/franzinc/agraph-tutorials/master/data/beings-languages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a33cff3-e659-4e49-ba11-24891c8fee2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Hobbitish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sindarin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Khuzdul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Westron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   language\n",
       "0   1  Hobbitish\n",
       "1   2   Sindarin\n",
       "2   3    Khuzdul\n",
       "3   4    Westron"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9460de45-e017-4115-aab4-7ab62d010d39",
   "metadata": {},
   "source": [
    "We convert these to triples as well, and add to the existing buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e438456a-11c0-4fcf-9a43-74e26e7377f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in languages_df.iterrows():\n",
    "    language_uri = conn.createURI(f\"http://franz.com/example-language/{str(row['id'])}\")\n",
    "    buffer.add_triple_to_buffer((language_uri, RDF.TYPE, f.Language))\n",
    "    buffer.add_triple_to_buffer((language_uri, RDFS.LABEL, row['language']))\n",
    "    buffer.add_triple_to_buffer((language_uri, f.languageName, row['language']))\n",
    "    \n",
    "buffer.flush_triples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d7d28-309b-4b4f-96fd-de901c4fb18d",
   "metadata": {},
   "source": [
    "We now examine the triples in Gruff again and see there is no connection between the languages and the beings who might speak those languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a78efc-885a-4c9b-a05b-b9aa8a1597a5",
   "metadata": {},
   "source": [
    "![languages-etl](images/languages-etl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f892138a-f5d3-4782-87ae-32a5a5ff6757",
   "metadata": {},
   "source": [
    "We create a dataframe that will match beings to languages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1866da8a-4e5e-4c38-b1bb-76fff762fd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>being_id</th>\n",
       "      <th>language_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    being_id  language_id\n",
       "0          1            2\n",
       "1          1            4\n",
       "2          2            1\n",
       "3          2            4\n",
       "4          3            2\n",
       "5          3            4\n",
       "6          4            3\n",
       "7          4            4\n",
       "8          5            1\n",
       "9          5            2\n",
       "10         5            3\n",
       "11         5            4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#speakers_df = pd.read_csv('data/beings-languages-mapping.csv')\n",
    "speakers_df = pd.read_csv('https://raw.githubusercontent.com/franzinc/agraph-tutorials/master/data/beings-languages-mapping.csv')\n",
    "speakers_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc000b3-d2d5-43c8-ae57-d4babadae13f",
   "metadata": {},
   "source": [
    "We use the IDs to recreate the URIs that already exist in the graph to create the connections!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c232abc2-8b9e-4b9c-8c20-befb47fb1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in speakers_df.iterrows():\n",
    "    buffer.add_triple_to_buffer((conn.createURI(f\"http://franz.com/example-being/{str(row['being_id'])}\"),\n",
    "                                 f.speaks,\n",
    "                                 conn.createURI(f\"http://franz.com/example-language/{str(row['language_id'])}\")))\n",
    "buffer.flush_triples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c06743-b4b6-453d-bcc6-d520e96f0fb2",
   "metadata": {},
   "source": [
    "Now looking in Gruff we see there is a connection between the beings and languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac3836a-4e98-460e-b320-516a12255e2e",
   "metadata": {},
   "source": [
    "![beings-languages-etl](images/beings-languages-etl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e2993-9c2c-4caf-a24a-0f6951de6fa9",
   "metadata": {},
   "source": [
    "### Add more depth with taxonomies! \n",
    "We want to know more information about all these languages. To do this we add a previously created taxonomy about Tolkien's various languages and then connect it to our existing data in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b3d87-ebbe-44cd-af39-80a64461ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.addFile('data/tolkien-languages.nt') #Use this if running notebook in Jupyter\n",
    "\n",
    "#use the following code if in Google Colab\n",
    "import requests\n",
    "url = 'https://raw.githubusercontent.com/franzinc/agraph-tutorials/master/data/tolkien-languages.nt'\n",
    "response = requests.get(url)\n",
    "with open('tolkien-languages.nt', 'w') as f: f.write(response.text)\n",
    "conn.addFile('tolkien-languages.nt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c0696-2b6f-4bc8-990e-76b179cf4dbf",
   "metadata": {},
   "source": [
    "![languages-taxonomy](images/languages-taxonomy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec96fed-89a9-498f-a80c-71d8ce35911e",
   "metadata": {},
   "source": [
    "Now we will connect the languages spoken by the various characters to the taxonomy. To do this we first create a mapping from language name to the ID of that concept in the taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdb10a4e-8cd1-48be-8178-c494d2e8d22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adûnic': <https://franz.com/example-taxonomy/lotr-languages/ed0b1aba-c6ef-47c6-b345-3df61a3cbdf4>,\n",
      " 'Avarin': <https://franz.com/example-taxonomy/lotr-languages/7602d400-02a1-410d-b008-c93c00018bb9>,\n",
      " 'Common Eldarin': <https://franz.com/example-taxonomy/lotr-languages/7f6f4ea8-53d4-45ec-b784-e23010d23b02>,\n",
      " 'Common Telerin': <https://franz.com/example-taxonomy/lotr-languages/bc0e54b2-d6f4-4d31-b535-75c46b11d8ab>,\n",
      " 'Common Tongue': <https://franz.com/example-taxonomy/lotr-languages/6f563122-6566-4b90-9e75-c6e11a3b85e1>,\n",
      " 'Dalish': <https://franz.com/example-taxonomy/lotr-languages/d9e87fca-4716-493c-8761-267afe99e464>,\n",
      " 'Drúedain of Brethil': <https://franz.com/example-taxonomy/lotr-languages/96063831-58a4-4a56-82e5-1e85e9353823>,\n",
      " 'Drûg Languages': <https://franz.com/example-taxonomy/lotr-languages/24b23271-fa90-4c0c-aac8-f89c112e6f75>,\n",
      " 'Dunlending': <https://franz.com/example-taxonomy/lotr-languages/0bc231b1-3f6b-4589-9024-14cc3ae4928b>,\n",
      " 'Easterlings': <https://franz.com/example-taxonomy/lotr-languages/b058f37f-c747-4bc1-83c1-1104afc24455>,\n",
      " 'Elvish Languages': <https://franz.com/example-taxonomy/lotr-languages/9837a883-4390-442c-8063-4976bb67234c>,\n",
      " 'Haladin': <https://franz.com/example-taxonomy/lotr-languages/cd5f442f-a521-4742-9807-dc8ed4e68893>,\n",
      " 'Haradrim Languages': <https://franz.com/example-taxonomy/lotr-languages/3301a638-bef1-4037-a2f4-210ed78197aa>,\n",
      " 'Hobbitish': <https://franz.com/example-taxonomy/lotr-languages/13458670-f4ee-43b1-97d4-2e5f07680e37>,\n",
      " 'Khuzdul': <https://franz.com/example-taxonomy/lotr-languages/a35400b2-312b-4e66-956b-fbeb56c40b0a>,\n",
      " 'Language of the Forefathers of the Second House of the Atanatari': <https://franz.com/example-taxonomy/lotr-languages/c09f83ff-2277-498d-af3a-637c758fdc31>,\n",
      " 'Languages of Forefathers of the First and Third Houses of Atanatári': <https://franz.com/example-taxonomy/lotr-languages/e4f00d6b-bd74-4a58-b49a-9c111c5b1ca1>,\n",
      " 'Languages of Men of Eriador during the Second Age': <https://franz.com/example-taxonomy/lotr-languages/ebb58747-6d9e-421e-afeb-90a99e9ff9c5>,\n",
      " 'Languages of Northmen': <https://franz.com/example-taxonomy/lotr-languages/6970c0a1-11bc-401c-b7e3-ce370cae6101>,\n",
      " 'Languages of the Ainur': <https://franz.com/example-taxonomy/lotr-languages/52144508-0522-45b8-8bb2-57399d408182>,\n",
      " 'Languages of the Ents': <https://franz.com/example-taxonomy/lotr-languages/bb253802-5a8a-43b6-acf5-ffe66ee20cc7>,\n",
      " 'Mannish Languages': <https://franz.com/example-taxonomy/lotr-languages/388d31fb-9419-49ac-8da3-35ff05495f91>,\n",
      " 'Nandorin Languages': <https://franz.com/example-taxonomy/lotr-languages/a26c04d0-b58a-4944-8742-a4ba58b00edf>,\n",
      " 'New Entish': <https://franz.com/example-taxonomy/lotr-languages/a86641f6-1982-4f79-8802-ca4b97dbb576>,\n",
      " 'Old Entish': <https://franz.com/example-taxonomy/lotr-languages/33ddf90b-bcbd-4358-9649-bf5d3646f4d5>,\n",
      " 'Quenya': <https://franz.com/example-taxonomy/lotr-languages/0a40cddd-932b-40c1-95ca-06096df43e6f>,\n",
      " 'Rohirric': <https://franz.com/example-taxonomy/lotr-languages/ab600421-ea04-428b-b1c6-b9c3405e7089>,\n",
      " 'Sindarin': <https://franz.com/example-taxonomy/lotr-languages/82cb2481-faaf-4f5f-8e1a-3772b805180d>,\n",
      " 'Taliska': <https://franz.com/example-taxonomy/lotr-languages/711e8200-2c27-4a77-a0c8-89e87da2a0cb>,\n",
      " 'Telerin of Valinor': <https://franz.com/example-taxonomy/lotr-languages/f2da3add-10bf-4adb-b182-0c6e568b16dc>,\n",
      " 'Tongue of Dwarves': <https://franz.com/example-taxonomy/lotr-languages/d508b345-37b6-42b4-ac0d-5120b56bdb6a>,\n",
      " 'Valarin': <https://franz.com/example-taxonomy/lotr-languages/ed800cc0-7cd2-42d6-b7ca-ddc752ed9497>,\n",
      " 'Vanyarin Quenya': <https://franz.com/example-taxonomy/lotr-languages/8589a10e-53e8-4f7a-992a-d5b624e5d596>,\n",
      " 'Westron': <https://franz.com/example-taxonomy/lotr-languages/6f563122-6566-4b90-9e75-c6e11a3b85e1>,\n",
      " 'Woses of Drúdan Forest': <https://franz.com/example-taxonomy/lotr-languages/8d3f97cc-b630-4015-9c4d-7a2b4bdd2984>,\n",
      " 'Ñoldorin Quenya': <https://franz.com/example-taxonomy/lotr-languages/a9f9f3c5-bd75-42ff-bd93-763296540bb8>}\n"
     ]
    }
   ],
   "source": [
    "query_string = \"\"\"select ?concept ?label where {\n",
    "                    { ?concept skos:prefLabel ?label . } UNION { ?concept skos:altLabel ?label } }\"\"\"\n",
    "result = conn.prepareTupleQuery(QueryLanguage.SPARQL, query_string).evaluate()\n",
    "languages = {}\n",
    "with result:\n",
    "    for binding_set in result:\n",
    "        concept = binding_set.getValue('concept')\n",
    "        label = binding_set.getValue('label').label\n",
    "        languages.update({label: concept})\n",
    "pprint(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4822b5e-2d04-4c7a-8d7b-a366924f8137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<https://franz.com/example-taxonomy/lotr-languages/6f563122-6566-4b90-9e75-c6e11a3b85e1>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages.get('Westron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c30973-dcbf-4201-bcb1-7de963c83b8a",
   "metadata": {},
   "source": [
    "Now we grab each language per character and connect it to the taxonomy using the `skos:exactMatch` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00080a8b-527a-4235-9b34-b7ca01993fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"\"\"select ?language ?languageName where {\n",
    "                    ?language <http://franz.com/example-etl/languageName> ?languageName }\"\"\"\n",
    "result = conn.prepareTupleQuery(QueryLanguage.SPARQL, query_string).evaluate()\n",
    "\n",
    "skosExactMatch = conn.createURI('http://www.w3.org/2004/02/skos/core#exactMatch')\n",
    "\n",
    "with result:\n",
    "    for binding_set in result:\n",
    "        language = binding_set.getValue('language')\n",
    "        language_name = binding_set.getValue('languageName').label\n",
    "        matching_language_uri = languages.get(language_name)\n",
    "        buffer.add_triple_to_buffer((language, skosExactMatch, matching_language_uri))\n",
    "buffer.flush_triples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69f31a-d7fb-4239-9f8a-c1b6116e19cc",
   "metadata": {},
   "source": [
    "![beings-with-taxonomy-languages](images/beings-with-taxonomy-languages.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e36fa35-408f-4e19-aae6-dda5d8564cee",
   "metadata": {},
   "source": [
    "Now as an example let's write a query that searches for all beings that speak an `Elvish Language`. Note that all languages are also part of a `Collection` of their broadest concept. First we have the visual query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa7f5c2-5989-433a-a25e-87bbbbacce80",
   "metadata": {},
   "source": [
    "![elvish-languages-query](images/elvish-languages-query.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff858f4a-49ca-4ca4-b0ad-db5bd145fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gandalf\n",
      "Legolas\n",
      "Aragorn\n"
     ]
    }
   ],
   "source": [
    "query_string = \"\"\"select ?name where\n",
    "{ <https://franz.com/example-taxonomy/lotr-languages/5aeb87e2-6bfb-488f-a708-07ac23d73bfe> skos:member ?taxonomyLanguage .\n",
    "  ?beingLanguage skos:exactMatch ?taxonomyLanguage .\n",
    "  ?being <http://franz.com/example-etl/speaks> ?beingLanguage ;\n",
    "         <http://franz.com/example-etl/name> ?name . }\"\"\"\n",
    "result = conn.prepareTupleQuery(QueryLanguage.SPARQL, query_string).evaluate()\n",
    "with result:\n",
    "    for binding_set in result: print(binding_set.getValue('name').label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40202d4-a5b8-4e20-a04b-d42f131852d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:synthea]",
   "language": "python",
   "name": "conda-env-synthea-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
