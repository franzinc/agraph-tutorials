{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection setup\n",
    "\n",
    "If you are connecting in a regular jupyter notebook and have activated our `ag-tutorial` environment then you do not need to run the following two cells to install `agraph-python` and `pandas`. However if you are in a **Google Colab** please run the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agraph-python pandas pycurl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section makes it possible to setup connection parameters. Values entered here will be saved in environment variables (and thus will be used as defaults by functions like `ag_connect()`. Depending on how you are connecting to an AllegroGraph repository the following variables will look slightly different. The following variables are an example of how to connect to a cloud server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: https://ag197y8xsj2epl2e.allegrograph.cloud\n",
      "Port: 443\n",
      "Username: admin\n",
      "Password: GrMEKDvQFaN2bkrHJeiCbv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def setup_env_var(var_name, value, description):\n",
    "    os.environ[var_name] = value\n",
    "    print(\"{}: {}\".format(description, value))\n",
    "    \n",
    "setup_env_var('AGRAPH_HOST', 'https://ag197y8xsj2epl2e.allegrograph.cloud', 'Hostname')\n",
    "setup_env_var('AGRAPH_PORT', '443', 'Port')\n",
    "setup_env_var('AGRAPH_USER', 'admin', 'Username')\n",
    "setup_env_var('AGRAPH_PASSWORD', 'GrMEKDvQFaN2bkrHJeiCbv', 'Password')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Creating a repository and triple indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing catalogs\n",
    "\n",
    "The first task is to attach to our AllegroGraph Server and open a\n",
    "repository. To achieve this we build a chain of Python objects, ending in\n",
    "a “connection” object that lets us manipulate triples in a specific\n",
    "repository. The overall process of generating the connection object\n",
    "follows this diagram:\n",
    "\n",
    "The first example opens (or\n",
    "creates) a repository by building a\n",
    "series of client-side objects,\n",
    "culminating in a “connection”\n",
    "object.\n",
    "\n",
    "The connection object contains the\n",
    "methods that let us manipulate\n",
    "triples in a specific repository.\n",
    "\n",
    "![images/connection.svg](images/connection.svg)\n",
    "\n",
    "Before we start, we will extract the location of the AG server from environment\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ag197y8xsj2epl2e.allegrograph.cloud\n"
     ]
    }
   ],
   "source": [
    "AGRAPH_HOST = os.environ.get('AGRAPH_HOST', 'localhost')\n",
    "AGRAPH_PORT = int(os.environ.get('AGRAPH_PORT', '10079'))\n",
    "AGRAPH_USER = os.environ.get('AGRAPH_USER', 'test')\n",
    "AGRAPH_PASSWORD = os.environ.get('AGRAPH_PASSWORD', 'xyzzy')\n",
    "print(AGRAPH_HOST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AllegroGraph connection functions use these environment variables as\n",
    "defaults, but we will pass the values explicitly to illustrate how to\n",
    "specify connection parameters in Python.\n",
    "\n",
    "The example first connects to an AllegroGraph Server by providing the\n",
    "endpoint (host IP address and port number) of an already-launched\n",
    "AllegroGraph server. This creates a client-side server object, which can\n",
    "access the AllegroGraph server’s list of available catalogs through the\n",
    "[listCatalogs()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.sail.html#franz.openrdf.sail.allegrographserver.AllegroGraphServer.listCatalogs) method. Note that the name of the root catalog\n",
    "will be represented by None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to AllegroGraph server -- host:'https://ag197y8xsj2epl2e.allegrograph.cloud' port:443\n",
      "Available catalogs:\n",
      "  - <root catalog>\n",
      "  - fedshard\n",
      "  - system\n",
      "[None, 'fedshard', 'system']\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.sail.allegrographserver import AllegroGraphServer\n",
    "\n",
    "print(\"Connecting to AllegroGraph server --\",\n",
    "      \"host:'%s' port:%s\" % (AGRAPH_HOST, AGRAPH_PORT))\n",
    "server = AllegroGraphServer(AGRAPH_HOST, AGRAPH_PORT,\n",
    "                            AGRAPH_USER, AGRAPH_PASSWORD)\n",
    "print(\"Available catalogs:\")\n",
    "for cat_name in server.listCatalogs():\n",
    "    if cat_name is None:\n",
    "        print('  - <root catalog>')\n",
    "    else:\n",
    "        print('  - ' + str(cat_name))\n",
    "        \n",
    "print(server.listCatalogs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output says that the server has the root catalog and possibly\n",
    "also some other catalogs that someone has created for some\n",
    "experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing repositories\n",
    "\n",
    "In the next part of this example, we use the [openCatalog()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.sail.html#franz.openrdf.sail.allegrographserver.AllegroGraphServer.openCatalog)\n",
    "method to create a client-side catalog object. In this example we will\n",
    "connect to the root catalog. When we look inside that catalog, we can\n",
    "see which repositories are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available repositories in catalog 'None':\n",
      "  - actors\n",
      "  - agraph-example\n",
      "  - python-tutorial\n",
      "  - test\n"
     ]
    }
   ],
   "source": [
    "catalog = server.openCatalog('')\n",
    "print(\"Available repositories in catalog '%s':\" % catalog.getName())\n",
    "for repo_name in catalog.listRepositories():\n",
    "    print('  - ' + repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding output lists the available repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating repositories\n",
    "\n",
    "The next step is to create a client-side repository object representing\n",
    "the respository we wish to open, by calling the [getRepository()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.sail.html#franz.openrdf.sail.allegrographserver.Catalog.getRepository)\n",
    "method of the catalog object. We have to provide the name of the desired\n",
    "repository ('python-tutorial'), and select one of four access modes:\n",
    "\n",
    "- Repository.RENEW clears the contents of an existing repository\n",
    "  before opening. If the indicated repository does not exist, it\n",
    "  creates one.  \n",
    "- Repository.OPEN opens an existing repository, or throws an\n",
    "  exception if the repository is not found.  \n",
    "- Repository.ACCESS opens an existing repository, or creates a new\n",
    "  one if the repository is not found.  \n",
    "- Repository.CREATE creates a new repository, or throws an\n",
    "  exception if one by that name already exists.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<franz.openrdf.repository.repository.Repository object at 0x7fffeddf5b70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from franz.openrdf.repository.repository import Repository\n",
    "\n",
    "mode = Repository.RENEW\n",
    "my_repository = catalog.getRepository('python-tutorial', mode)\n",
    "my_repository.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new or renewed repository must be initialized, using the\n",
    "[initialize()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repository.Repository.initialize) method of the repository object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a repository\n",
    "\n",
    "The goal of all this object-building has been to create a client-side\n",
    "connection object, whose methods let us manipulate the triples of the\n",
    "repository. The repository object’s [getConnection()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repository.Repository.getConnection) method\n",
    "returns this connection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository python-tutorial is up!\n",
      "It contains 0 statement(s).\n"
     ]
    }
   ],
   "source": [
    "conn = my_repository.getConnection()\n",
    "print('Repository %s is up!' % my_repository.getDatabaseName())\n",
    "print('It contains %d statement(s).' % conn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [size()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.size) method of the connection object returns how many\n",
    "triples are present. In the example1() function, this number\n",
    "will always be zero because we “renewed” the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing indices\n",
    "\n",
    "Whenever you create a new repository, you should stop to consider which\n",
    "kinds of triple indices you will need. This is an important efficiency\n",
    "decision. AllegroGraph uses a set of sorted indices to quickly identify\n",
    "a contiguous range of triples that are likely to match a specific query\n",
    "pattern.\n",
    "\n",
    "These indices are identified by names that describe their organization.\n",
    "The default set of indices are called **spogi, posgi, ospgi, gspoi,\n",
    "gposi, gospi**, and **i** , where:\n",
    "\n",
    "- **S** stands for the subject URI.  \n",
    "- **P** stands for the predicate URI.  \n",
    "- **O** stands for the object URI or literal.  \n",
    "- **G** stands for the graph URI.  \n",
    "- **I** stands for the triple identifier (its unique id number within the\n",
    "  triple store).  \n",
    "  \n",
    "\n",
    "The order of the letters denotes how the index has been organized. For\n",
    "instance, the **spogi** index contains all of the triples in the\n",
    "store, sorted first by subject, then by predicate, then by object, and\n",
    "finally by graph. The triple id number is present as a fifth column in\n",
    "the index. If you know the URI of a desired resource (the *subject*\n",
    "value of the query pattern), then the **spogi** index lets you quickly\n",
    "locate and retrieve all triples with that subject.\n",
    "\n",
    "The idea is to provide your respository with the indices that your\n",
    "queries will need, and to avoid maintaining indices that you will never\n",
    "need.\n",
    "\n",
    "We can use the connection object’s [listValidIndices()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.listValidIndices) method to\n",
    "examine the list of all possible AllegroGraph triple indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spogi', 'spgoi', 'sopgi', 'sogpi', 'sgpoi', 'sgopi', 'psogi', 'psgoi', 'posgi', 'pogsi', 'pgsoi', 'pgosi', 'ospgi', 'osgpi', 'opsgi', 'opgsi', 'ogspi', 'ogpsi', 'gspoi', 'gsopi', 'gpsoi', 'gposi', 'gospi', 'gopsi', 'i']\n",
      "All valid triple indices:\n",
      "   spogi spgoi sopgi sogpi sgpoi\n",
      "   sgopi psogi psgoi posgi pogsi\n",
      "   pgsoi pgosi ospgi osgpi opsgi\n",
      "   opgsi ogspi ogpsi gspoi gsopi\n",
      "   gpsoi gposi gospi gopsi i\n"
     ]
    }
   ],
   "source": [
    "indices = conn.listValidIndices()\n",
    "print(indices)\n",
    "group_size = 5\n",
    "print('All valid triple indices:')\n",
    "for offset in range(0, len(indices), group_size):\n",
    "    group = indices[offset:offset + group_size]\n",
    "    print('  ', ' '.join(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the list of all possible valid indices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AllegroGraph can generate any of these indices if you need them, but it\n",
    "creates only seven indices by default. We can see the current indices\n",
    "by using the connection object’s [listIndices()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.listIndices) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current triple indices: i, gposi, gspoi, ospgi, posgi, psogi, spogi\n"
     ]
    }
   ],
   "source": [
    "indices = conn.listIndices()\n",
    "print('Current triple indices:', ', '.join(indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently seven indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices that begin with “g” are sorted primarily by subgraph (or\n",
    "“context”). If your application does not use subgraphs, you should\n",
    "consider removing these indices from the repository. You don’t want to\n",
    "build and maintain triple indices that your application will never use.\n",
    "This wastes CPU time and disk space. The connection object has a\n",
    "convenient [dropIndex()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.dropIndex) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing graph indices...\n",
      "Current triple indices: i, ospgi, posgi, psogi, spogi\n"
     ]
    }
   ],
   "source": [
    "print(\"Removing graph indices...\")\n",
    "conn.dropIndex(\"gospi\")\n",
    "conn.dropIndex(\"gposi\")\n",
    "conn.dropIndex(\"gspoi\")\n",
    "indices = conn.listIndices()\n",
    "print('Current triple indices:', ', '.join(indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having dropped three of the triple indices, there are now four\n",
    "remaining:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **i** index is for deleting triples by using the triple id number.\n",
    "It is also required for [free text indexing](#example12).  The\n",
    "**ospgi** index is sorted primarily by object value, which makes it\n",
    "possible to efficiently retrieve a range of object values from the\n",
    "index. Similarly, the **posgi** index lets us quickly reach for a\n",
    "triples that all share the same predicate. We mentioned previously\n",
    "that the **spogi** index speeds up the retrieval of triples that all\n",
    "have the same subject URI.\n",
    "\n",
    "As it happens, we may have been overly hasty in eliminating all of the\n",
    "graph indices. AllegroGraph can find the right matches as long as there\n",
    "is *any* one index present, but using the “right” index is much faster.\n",
    "Let’s put one of the graph indices back, just in case we need it. We’ll\n",
    "use the connection object’s [addIndex()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addIndex) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding one graph index back in...\n",
      "Current triple indices: i, gspoi, ospgi, posgi, psogi, spogi\n"
     ]
    }
   ],
   "source": [
    "print(\"Adding one graph index back in...\")\n",
    "conn.addIndex(\"gspoi\")\n",
    "indices = conn.listIndices()\n",
    "print('Current triple indices:', ', '.join(indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Releasing resources\n",
    "\n",
    "Both the connection and the repository object must be closed to\n",
    "release resources once they are no longer needed. We can use the\n",
    "[shutDown()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repository.Repository.shutDown) and [close()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.close)\n",
    "methods to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "my_repository.shutDown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is safer and more convenient to ensure that the resources are\n",
    "released by using the with statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statements: 0\n"
     ]
    }
   ],
   "source": [
    "with catalog.getRepository('python-tutorial', Repository.OPEN) as repo:\n",
    "    # Note: an explicit call to initialize() is not required\n",
    "    # when using the `with` statement.\n",
    "    with repo.getConnection() as conn:\n",
    "        print('Statements:', conn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "Creating the intermediate server, catalog and repository objects can\n",
    "be tedious when the only thing required is a single connection to one\n",
    "repository. In such circumstances it might be more convenient to use\n",
    "the [ag_connect()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.html#franz.openrdf.connect.ag_connect) function. That is what we will do in further\n",
    "examples. Here is a brief example of using [ag_connect()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.html#franz.openrdf.connect.ag_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statements: 0\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "with ag_connect('python-tutorial', create=True, clear=True) as conn:\n",
    "    print('Statements:', conn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function take care of creating all required objects and the\n",
    "returned context manager ensures that all necessary initialization\n",
    "steps are taken and no resources are leaked. The create and\n",
    "clear arguments ensure that the repository is empty and that it is\n",
    "created if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Asserting and retracting triples\n",
    "\n",
    "In this example we show how to create resources describing two people,\n",
    "Bob and Alice, by asserting triples into the repository. The example\n",
    "also retracts and replaces a triple. Assertions and retractions to the\n",
    "triple store are executed by [add()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.add) and [remove()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.remove) methods\n",
    "belonging to the connection object, which we obtain by calling the\n",
    "ag_connect() function described in [Example 1: Creating a repository and triple indices](#example1).\n",
    "\n",
    "Before asserting a triple, we have to generate the URI values for the\n",
    "subject, predicate and object fields. The AllegroGraph Python client\n",
    "API predefines a number of classes and predicates for the RDF, RDFS,\n",
    "XSD, and OWL ontologies. RDF.TYPE is one of the predefined\n",
    "predicates we will use.\n",
    "\n",
    "The [add()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.add) and [remove()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.remove) methods take an optional\n",
    "contexts argument that specifies one or more subgraphs that are\n",
    "the target of triple assertions and retractions. When the context is\n",
    "omitted, triples are asserted/retracted to/from the default graph. In\n",
    "the example below, facts about Alice and Bob reside in the default\n",
    "graph.\n",
    "\n",
    "The second example begins by calling ag_connect() to create the\n",
    "appropriate connection object, which is bound to the variable conn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to begin assembling the URIs we will need for the new\n",
    "triples. The [createURI()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.createURI) method generates a URI from a string.\n",
    "These are the subject URIs identifying the resources “Bob” and “Alice”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://example.org/people/alice>\n"
     ]
    }
   ],
   "source": [
    "alice = conn.createURI(\"http://example.org/people/alice\")\n",
    "bob = conn.createURI(\"http://example.org/people/bob\")\n",
    "print(alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bob and Alice will be members of the “person” class (rdf type\n",
    "person)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = conn.createURI(\"http://example.org/ontology/Person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Bob and Alice will have a “name” attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = conn.createURI(\"http://example.org/ontology/name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name attributes will contain literal values. We have to generate the\n",
    "[Literal](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.model.html#franz.openrdf.model.Literal) objects from strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bobsName = conn.createLiteral(\"Bob\")\n",
    "alicesName = conn.createLiteral(\"Alice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line prints out the number of triples currently in the\n",
    "repository - we expect that to be zero, since we have not yet added\n",
    "any triples and the connect function should have removed any\n",
    "existing statements from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple count before inserts: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Triple count before inserts:\", conn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we assert four triples, two for Bob and two more for Alice, using\n",
    "the connection object’s [add()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.add) method. After\n",
    "the assertions, we count triples again (there should be four) and print\n",
    "out the triples for inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple count: 4\n",
      "(<http://example.org/people/bob>, <http://example.org/ontology/name>, \"Bob\")\n",
      "(<http://example.org/people/alice>, <http://example.org/ontology/name>, \"Alice\")\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.vocabulary import RDF\n",
    "\n",
    "# alice is a person\n",
    "conn.add(alice, RDF.TYPE, person)\n",
    "# alice's name is \"Alice\"\n",
    "conn.add(alice, name, alicesName)\n",
    "# bob is a person\n",
    "conn.add(bob, RDF.TYPE, person)\n",
    "# bob's name is \"Bob\":\n",
    "conn.add(bob, name, bobsName)\n",
    "\n",
    "print(\"Triple count:\", conn.size())\n",
    "for s in conn.getStatements(None, name, None, None):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The None arguments to the [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) method say that we\n",
    "don’t want to restrict what values may be present in the subject, predicate,\n",
    "object or context positions. Just print out all the triples where the predicate is `name`\n",
    "\n",
    "This is the output at this point. We see four triples, two about Alice\n",
    "and two about Bob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see two resources of type “person,” each with a literal name.\n",
    "\n",
    "The next step is to demonstrate how to remove a triple. Use the\n",
    "[remove()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.remove) method of the connection object, and supply a triple pattern\n",
    "that matches the target triple. In this case we want to remove Bob’s name\n",
    "triple from the repository. Then we’ll count the triples again to verify\n",
    "that there are only three remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple count: 3\n"
     ]
    }
   ],
   "source": [
    "conn.remove(bob, name, bobsName)\n",
    "print(\"Triple count:\", conn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potentially less verbose way of adding triples is to use the\n",
    "[addData()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addData) method of the connection object with a string\n",
    "containing triples in [Turtle](https://www.w3.org/TR/turtle/), [N-Triples](https://www.w3.org/TR/n-triples/) or another RDF format.\n",
    "\n",
    "Let us see how the data used in this example could be added using\n",
    "[addData()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addData). We will also wrap the whole process in a function\n",
    "that we’ll use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bob_and_alice(conn):\n",
    "   conn.addData(\"\"\"\n",
    "       @base <http://example.org/> .\n",
    "\n",
    "       <people/alice> a <ontology/Person> ;\n",
    "                      <ontology/name> \"Alice\" .\n",
    "       <people/bob> a <ontology/Person> ;\n",
    "                    <ontology/name> \"Bob\" .\n",
    "   \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string used here is in the [Turtle](https://www.w3.org/TR/turtle/) format. It is also possible\n",
    "to use other formats by passing the rdf_format argument to\n",
    "[addData()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addData).\n",
    "\n",
    "We should check if the new function behaves as expected by creating a\n",
    "fresh connection (recall that the clear parameter causes all existing\n",
    "triples to be deleted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triple count: 4\n"
     ]
    }
   ],
   "source": [
    "with ag_connect('python-tutorial', clear=True) as conn:\n",
    "    add_bob_and_alice(conn)\n",
    "    print(\"Triple count:\", conn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: A SPARQL query\n",
    "\n",
    "SPARQL stands for the [“SPARQL Protocol and RDF Query Language,”](http://www.w3.org/TR/rdf-sparql-query/) a recommendation of the\n",
    "[World Wide Web Consortium (W3C)](http://www.w3.org/) . SPARQL is a\n",
    "query language for retrieving RDF triples.\n",
    "\n",
    "Our next example illustrates how to evaluate a SPARQL query. This is\n",
    "the simplest query, the one that returns all triples. Note that we\n",
    "will use the same triples that were used in [Example 2: Asserting and retracting triples](#example2).\n",
    "\n",
    "Let’s create the connection first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can add our data and define the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "    @base <http://example.org/> .\n",
    "\n",
    "    <people/alice> a <ontology/Person> ;\n",
    "                   <ontology/name> \"Alice\" .\n",
    "    <people/bob> a <ontology/Person> ;\n",
    "                 <ontology/name> \"Bob\" .\n",
    "\"\"\")\n",
    "query_string = \"SELECT ?s ?p ?o  WHERE {?s ?p ?o .}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SELECT clause returns the variables ?s, ?p and ?o\n",
    "in the binding set. The variables are bound to the subject, predicate\n",
    "and objects values of each triple that satisfies the WHERE clause. In\n",
    "this case the WHERE clause is unconstrained. The dot (.) in the\n",
    "fourth position signifies the end of the pattern.\n",
    "\n",
    "The connection object’s [prepareTupleQuery()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.prepareTupleQuery) method creates a\n",
    "query object that can be evaluated one or more times. The results are\n",
    "returned in an iterator that yields a sequence of binding sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.query.query import QueryLanguage\n",
    "\n",
    "tuple_query = conn.prepareTupleQuery(QueryLanguage.SPARQL, query_string)\n",
    "result = tuple_query.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we illustrate one method for extracting the values from a\n",
    "binding set, indexed by the name of the corresponding column variable\n",
    "in the SELECT clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http://example.org/people/alice> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/ontology/Person>\n",
      "<http://example.org/people/alice> <http://example.org/ontology/name> \"Alice\"\n",
      "<http://example.org/people/bob> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/ontology/Person>\n",
      "<http://example.org/people/bob> <http://example.org/ontology/name> \"Bob\"\n"
     ]
    }
   ],
   "source": [
    "with result:\n",
    "   for binding_set in result:\n",
    "        s = binding_set.getValue(\"s\")\n",
    "        p = binding_set.getValue(\"p\")\n",
    "        o = binding_set.getValue(\"o\")\n",
    "        print(\"%s %s %s\" % (s, p, o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have wrapped the whole result processing in a with\n",
    "statement. The reason is that result objects must be closed after\n",
    "processing to release resources. The most convenient way to ensure\n",
    "this is the with statement, but it is also possible to explicitly\n",
    "call [close()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.queryresult.QueryResult.close)\n",
    "(e.g. in a finally block).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Statement matching\n",
    "\n",
    "The [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) method of the connection object provides a\n",
    "simple way to perform unsophisticated queries. This method lets you\n",
    "enter a mix of required values and wildcards, and retrieve all\n",
    "matching triples. (If you need to perform sophisticated tests and\n",
    "comparisons you should use a SPARQL query instead.)\n",
    "\n",
    "Below, we illustrate two kinds of [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) calls. The\n",
    "first mimics traditional RDF4J syntax, and returns a [Statement](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.model.html#franz.openrdf.model.Statement)\n",
    "object at each iteration. We will reuse data from in previous\n",
    "examples to create a connection object and populate the repository\n",
    "with four triples describing Bob and Alice. We’re going to search for\n",
    "triples that mention Alice, so we have to create an “Alice” URI to use\n",
    "in the search pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "    @base <http://example.org/> .\n",
    "\n",
    "    <people/alice> a <ontology/Person> ;\n",
    "                   <ontology/name> \"Alice\" .\n",
    "    <people/bob> a <ontology/Person> ;\n",
    "                 <ontology/name> \"Bob\" .\n",
    "\"\"\")\n",
    "alice = conn.createURI(\"http://example.org/people/alice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search for triples with Alice’s URI in the subject\n",
    "position. The None values are wildcards for the predicate and\n",
    "object positions of the triple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = conn.getStatements(alice, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) method returns a RepositoryResult object\n",
    "(bound to the variable statements in this case). This object can\n",
    "be iterated over, exposing one result statement at a time. It is\n",
    "sometimes desirable to screen the results for duplicates, using the\n",
    "[enableDuplicateFilter()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.repositoryresult.RepositoryResult.enableDuplicateFilter) method. Note, however, that duplicate\n",
    "filtering can be expensive. Our example does not contain any\n",
    "duplicates, but it is possible for them to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<http://example.org/people/alice>, <http://example.org/ontology/name>, \"Alice\")\n",
      "(<http://example.org/people/alice>, <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>, <http://example.org/ontology/Person>)\n"
     ]
    }
   ],
   "source": [
    "with statements:\n",
    "    statements.enableDuplicateFilter()\n",
    "    for statement in statements:\n",
    "        print(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints out the two matching triples for “Alice.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we used the with keyword to ensure that the\n",
    "RepositoryResult object is closed after the results are\n",
    "fetched. This is necessary to release resources used during result\n",
    "retrieval. The same goal could be accomplished by calling the\n",
    "[RepositoryResult.close()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.repositoryresult.RepositoryResult.close) method (preferably in a finally\n",
    "block to ensure exception safety).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5: Literal values\n",
    "\n",
    "The next example illustrates some variations on what we have seen so\n",
    "far. The example creates and asserts plain, data-typed, and\n",
    "language-tagged literals, and then conducts searches for them in three\n",
    "ways:\n",
    "\n",
    "- [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) search, which is an efficient way to match a\n",
    "  single triple pattern.  \n",
    "  - SPARQL direct match, for efficient multi-pattern search.  \n",
    "  - SPARQL filter match, for sophisticated filtering such as\n",
    "  performing range matches.  \n",
    "  \n",
    "\n",
    "The [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) and SPARQL direct searches return exactly\n",
    "the datatype you ask for. The SPARQL filter queries can sometimes\n",
    "return multiple datatypes. This behavior will be one focus of this\n",
    "section.\n",
    "\n",
    "If you are not explicit about the datatype of a value, either when\n",
    "asserting the triple or when writing a search pattern, AllegroGraph\n",
    "will deduce an appropriate datatype and use it. This is another focus\n",
    "of this section. This helpful behavior can sometimes surprise you with\n",
    "unanticipated results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by obtaining a connection object and remvoing all existing data\n",
    "from the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of coding efficiency, it is good practice to create variables\n",
    "for namespace strings. We’ll use this namespace again and again in the\n",
    "following example. We have made the URIs in this example very short to\n",
    "keep the result displays compact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exns = \"ex://\"\n",
    "conn.setNamespace('ex', exns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namespace handling, including the [setNamespace()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.setNamespace) method, is\n",
    "described in [Example 11: Namespaces](#example11).\n",
    "\n",
    "The example will use an artificial data set consisting of eight\n",
    "statements, each illustrating a different kind of literal. The subject\n",
    "will describe the nature of the literal used as the object, while the\n",
    "predicate will always be `<ex://p>`. The example shows how to enter\n",
    "a full URI string, or alternately how to combine a namespace with a\n",
    "local resource name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_integer = conn.createURI(\"ex://integer\")\n",
    "ex_double = conn.createURI(\"ex://double\")\n",
    "ex_int = conn.createURI(\"ex://int\")\n",
    "ex_long = conn.createURI(\n",
    "    namespace=exns, localname=\"long\")\n",
    "ex_float = conn.createURI(\n",
    "    namespace=exns, localname=\"float\")\n",
    "ex_decimal = conn.createURI(\n",
    "    namespace=exns, localname=\"decimal\")\n",
    "ex_string = conn.createURI(\n",
    "    namespace=exns, localname=\"string\")\n",
    "ex_plain = conn.createURI(\n",
    "    namespace=exns, localname=\"plain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicate for all our statements will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = conn.createURI(namespace=exns, localname=\"p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct the objects, illustrating various kinds of RDF\n",
    "literals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.vocabulary.xmlschema import XMLSchema\n",
    "\n",
    "# Type will be XMLSchema.INTEGER\n",
    "forty_two = conn.createLiteral(42)\n",
    "# Type will be XMLSchema.DOUBLE\n",
    "forty_two_double = conn.createLiteral(42.0)\n",
    "forty_two_int = conn.createLiteral(\n",
    "    '42', datatype=XMLSchema.INT)\n",
    "forty_two_long = conn.createLiteral(\n",
    "    '42', datatype=XMLSchema.LONG)\n",
    "forty_two_float = conn.createLiteral(\n",
    "    '42', datatype=XMLSchema.FLOAT)\n",
    "forty_two_decimal = conn.createLiteral(\n",
    "    '42', datatype=XMLSchema.DECIMAL)\n",
    "forty_two_string = conn.createLiteral(\n",
    "    '42', datatype=XMLSchema.STRING)\n",
    "# Creates a plain (untyped) literal.\n",
    "forty_two_plain = conn.createLiteral('42')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In four of these statements, we explicitly identified the datatype of\n",
    "the value in order to create an INT, a LONG, a FLOAT and a\n",
    "STRING. This is the best practice.\n",
    "\n",
    "In three other statements, we just handed AllegroGraph numeric-looking\n",
    "values to see what it would do with them. As we will see in a moment,\n",
    "42 creates an INTEGER, 42.0 becomes a DOUBLE, and '42'\n",
    "becomes a “plain” (untyped) literal value.\n",
    "\n",
    "Note that plain literals are not *quite* the same thing\n",
    "as typed literal strings. A search for a plain literal\n",
    "will not always match a typed string, and *vice versa*.)\n",
    "\n",
    "Now we will now assemble the URIs and values into [statements](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.model.html#franz.openrdf.model.Statement) (which are client-side triples):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt1 = conn.createStatement(ex_integer, pred, forty_two)\n",
    "stmt2 = conn.createStatement(ex_double, pred, forty_two_double)\n",
    "stmt3 = conn.createStatement(ex_int, pred, forty_two_int)\n",
    "stmt4 = conn.createStatement(ex_long, pred, forty_two_long)\n",
    "stmt5 = conn.createStatement(ex_float, pred, forty_two_float)\n",
    "stmt6 = conn.createStatement(ex_decimal, pred, forty_two_decimal)\n",
    "stmt7 = conn.createStatement(ex_string, pred, forty_two_string)\n",
    "stmt8 = conn.createStatement(ex_plain, pred, forty_two_plain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then add the statements to the triple store on the AllegroGraph\n",
    "server. We can use either [add()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.add) or [addStatement()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addStatement) for this\n",
    "purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.add(stmt1)\n",
    "conn.add(stmt2)\n",
    "conn.add(stmt3)\n",
    "conn.addStatement(stmt4)\n",
    "conn.addStatement(stmt5)\n",
    "conn.addStatement(stmt6)\n",
    "conn.addStatement(stmt7)\n",
    "conn.addStatement(stmt8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll complete the round trip to see what triples we get back from\n",
    "these assertions. This is where we use [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) in this\n",
    "example to retrieve and display triples for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing all triples using getStatements(). Eight matches.\n",
      "<ex://plain> <ex://p> \"42\" .\n",
      "<ex://string> <ex://p> \"42\"^^<http://www.w3.org/2001/XMLSchema#string> .\n",
      "<ex://decimal> <ex://p> \"42.0\"^^<http://www.w3.org/2001/XMLSchema#decimal> .\n",
      "<ex://float> <ex://p> \"4.2E1\"^^<http://www.w3.org/2001/XMLSchema#float> .\n",
      "<ex://long> <ex://p> \"42\"^^<http://www.w3.org/2001/XMLSchema#long> .\n",
      "<ex://int> <ex://p> \"42\"^^<http://www.w3.org/2001/XMLSchema#int> .\n",
      "<ex://double> <ex://p> \"4.2E1\"^^<http://www.w3.org/2001/XMLSchema#double> .\n",
      "<ex://integer> <ex://p> \"42\"^^<http://www.w3.org/2001/XMLSchema#integer> .\n"
     ]
    }
   ],
   "source": [
    "print(\"Showing all triples using getStatements(). Eight matches.\")\n",
    "conn.getStatements(None, pred, None, output=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code prints out all triples from the store. The output\n",
    "parameter causes the result to be printed on stdout (it is also\n",
    "possible to pass a file name or a file-like object as the value of\n",
    "this parameter to print to other destinations). Without output the\n",
    "result would have been returned as a RepositoryResult object.\n",
    "\n",
    "Note that the retrieved literals are of eight types: an int (a 32-bit\n",
    "integer), an integer (arbitrary precision), a decimal, a long, a\n",
    "float, a double, a string, and a “plain literal.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ask for a specific datatype, you will get it. If you leave the\n",
    "decision up to AllegroGraph, you might get something unexpected such as\n",
    "a plain literal value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric literal values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching 42 without explicit type\n",
    "\n",
    "This section explores [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) and SPARQL matches against\n",
    "numeric triples. We ask AllegroGraph to find an untyped number,\n",
    "42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://integer> <ex://p> \"42\"^^<http://www.w3.org/2001/XMLSchema#integer> .\n",
      "\n",
      "SPARQL direct match\n",
      "--------------\n",
      "| s          |\n",
      "==============\n",
      "| ex:integer |\n",
      "--------------\n",
      "\n",
      "SPARQL filter match\n",
      "-----------------------------\n",
      "| s          | p    | o     |\n",
      "=============================\n",
      "| ex:integer | ex:p | 42    |\n",
      "| ex:double  | ex:p | 4.2E1 |\n",
      "| ex:int     | ex:p | 42    |\n",
      "| ex:long    | ex:p | 42    |\n",
      "| ex:float   | ex:p | 4.2E1 |\n",
      "| ex:decimal | ex:p | 42.0  |\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, pred, 42, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s ?p 42 .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = 42)}',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the executeQuery() method to retrieve the result of a\n",
    "SPARQL query. Like [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements), it accepts an output\n",
    "parameter that causes the result to be printed (instead of being\n",
    "returned as a [TupleQueryResult](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.queryresult.TupleQueryResult) object).  Here is what the query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) query returned triples containing longs\n",
    "only. The SPARQL direct match treated the numeric literal as if it had\n",
    "the type of <http://www.w3.org/2001/XMLSchema#integer> (see the\n",
    "SPARQL [specification](https://www.w3.org/TR/sparql11-query/#QSynLiterals) for\n",
    "information on how literals are parsed in queries) and returned only\n",
    "triples with exactly the same type. The SPARQL filter match, however,\n",
    "opened the doors to matches of multiple numeric types, and returned\n",
    "ints, floats, longs and doubles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching 42.0 without explicit type\n",
    "\n",
    "Now we will try the same queries using 42.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://double> <ex://p> \"4.2E1\"^^<http://www.w3.org/2001/XMLSchema#double> .\n",
      "\n",
      "SPARQL direct match\n",
      "--------------\n",
      "| s          |\n",
      "==============\n",
      "| ex:decimal |\n",
      "--------------\n",
      "\n",
      "SPARQL filter match\n",
      "-----------------------------\n",
      "| s          | p    | o     |\n",
      "=============================\n",
      "| ex:integer | ex:p | 42    |\n",
      "| ex:double  | ex:p | 4.2E1 |\n",
      "| ex:int     | ex:p | 42    |\n",
      "| ex:long    | ex:p | 42    |\n",
      "| ex:float   | ex:p | 4.2E1 |\n",
      "| ex:decimal | ex:p | 42.0  |\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, pred, 42.0, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s <ex://p> 42.0 .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s ?p ?o WHERE {?s ?p ?o . filter (?o = 42.0)}',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the query methods discussed in this example would\n",
    "return:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) search returned a double but not the similar\n",
    "float. Direct SPARQL match treated 42.0 as a decimal (in\n",
    "accordance with the SPARQL specification). The filter match returned\n",
    "all numeric types that were equal to 42.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching “42”^^xsd:int\n",
    "\n",
    "The next section shows the results obtained when querying for a\n",
    "literal with explicitly specified type. Note that doing this with\n",
    "[getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) requires passing in a [Literal](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.model.html#franz.openrdf.model.Literal) object,\n",
    "not a raw value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://int> <ex://p> \"42\"^^<http://www.w3.org/2001/XMLSchema#int> .\n",
      "\n",
      "SPARQL direct match\n",
      "----------\n",
      "| s      |\n",
      "==========\n",
      "| ex:int |\n",
      "----------\n",
      "\n",
      "SPARQL filter match\n",
      "-----------------------------\n",
      "| s          | p    | o     |\n",
      "=============================\n",
      "| ex:integer | ex:p | 42    |\n",
      "| ex:double  | ex:p | 4.2E1 |\n",
      "| ex:int     | ex:p | 42    |\n",
      "| ex:long    | ex:p | 42    |\n",
      "| ex:float   | ex:p | 4.2E1 |\n",
      "| ex:decimal | ex:p | 42.0  |\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, pred, forty_two_int, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s ?p \"42\"^^xsd:int .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?p ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"42\"^^xsd:int)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the query methods discussed in this example would\n",
    "return:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would get similar results when asking for any other typed literal\n",
    "(forty_two_long, forty_two_float, …)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric strings and plain literals\n",
    "\n",
    "At this point we are transitioning from tests of numeric matches to\n",
    "tests of string matches, but there is a gray zone to be explored\n",
    "first. What do we find if we search for strings that contain numbers?\n",
    "In particular, what about “plain literal” values that are almost, but\n",
    "not quite, strings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching “42” as a typed string\n",
    "\n",
    "Let’s start with a typed string literal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://string> <ex://p> \"42\"^^<http://www.w3.org/2001/XMLSchema#string> .\n",
      "\n",
      "SPARQL direct match\n",
      "-------------\n",
      "| s         |\n",
      "=============\n",
      "| ex:plain  |\n",
      "| ex:string |\n",
      "-------------\n",
      "\n",
      "SPARQL filter match\n",
      "------------------------------------------------------------------\n",
      "| s         | p    | o                                           |\n",
      "==================================================================\n",
      "| ex:string | ex:p | 42^^http://www.w3.org/2001/XMLSchema#string |\n",
      "| ex:plain  | ex:p | 42                                          |\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, pred, forty_two_string, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s ?p \"42\"^^xsd:string .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?p ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"42\"^^xsd:string)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPARQL matched both plain and literal strings, but a\n",
    "[getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) search returned only typed matches. In both\n",
    "cases numeric literals were ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching “42” as a plain literal\n",
    "\n",
    "If we try to match a plain (untyped) string value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://plain> <ex://p> \"42\" .\n",
      "\n",
      "SPARQL direct match\n",
      "-------------\n",
      "| s         |\n",
      "=============\n",
      "| ex:string |\n",
      "| ex:plain  |\n",
      "-------------\n",
      "\n",
      "SPARQL filter match\n",
      "------------------------------------------------------------------\n",
      "| s         | p    | o                                           |\n",
      "==================================================================\n",
      "| ex:string | ex:p | 42^^http://www.w3.org/2001/XMLSchema#string |\n",
      "| ex:plain  | ex:p | 42                                          |\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, pred, forty_two_plain, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s ?p \"42\" .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?p ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"42\")\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get results consistent with that we saw in the typed case:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SPARQL both kinds of string literals were matched, while\n",
    "[getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) returned only direct matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching strings\n",
    "\n",
    "In this section we’ll set up a variety of string triples and\n",
    "experiment with matching them using [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) and SPARQL.\n",
    "\n",
    "[Example 12: Free Text indexing](#example12) is a different topic. In this section we’re\n",
    "doing simple matches of whole strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample data\n",
    "\n",
    "For these examples we will use a different data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = conn.createURI('ex://name')\n",
    "upper_g = conn.createLiteral('Galadriel')\n",
    "lower_g = conn.createLiteral('galadriel')\n",
    "typed_g = conn.createLiteral('Galadriel', XMLSchema.STRING)\n",
    "lang_g = conn.createLiteral('Galadriel', language='sjn')\n",
    "upper_a = conn.createLiteral('Artanis')\n",
    "lower_a = conn.createLiteral('artanis')\n",
    "typed_a = conn.createLiteral('Artanis', XMLSchema.STRING)\n",
    "lang_a = conn.createLiteral('Artanis', language='qya')\n",
    "conn.addTriple('<ex://upper_g>', name, upper_g)\n",
    "conn.addTriple('<ex://lower_g>', name, lower_g)\n",
    "conn.addTriple('<ex://typed_g>', name, typed_g)\n",
    "conn.addTriple('<ex://lang_g>', name, lang_g)\n",
    "conn.addTriple('<ex://upper_a>', name, upper_a)\n",
    "conn.addTriple('<ex://lower_a>', name, lower_a)\n",
    "conn.addTriple('<ex://typed_a>', name, typed_a)\n",
    "conn.addTriple('<ex://lang_a>', name, lang_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two literals, each in four variants:\n",
    "\n",
    "- Upper case (plain literal)  \n",
    "  - Lower case (plain literal)  \n",
    "  - Typed  \n",
    "  - Tagged with a [BCP47](https://tools.ietf.org/html/bcp47) language tag appropriate for its language\n",
    "  (Quenya or Sindarin) according to the the [registry](https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching a plain string\n",
    "\n",
    "We’ve seen a similar case when looking at matches for \"42\", but\n",
    "this time we have more similar literals in the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://upper_g> <ex://name> \"Galadriel\" .\n",
      "\n",
      "SPARQL direct match\n",
      "--------------\n",
      "| s          |\n",
      "==============\n",
      "| ex:typed_g |\n",
      "| ex:upper_g |\n",
      "--------------\n",
      "\n",
      "SPARQL filter match\n",
      "-------------------------------------------------------------------\n",
      "| s          | o                                                  |\n",
      "===================================================================\n",
      "| ex:typed_g | Galadriel^^http://www.w3.org/2001/XMLSchema#string |\n",
      "| ex:upper_g | Galadriel                                          |\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, name, upper_g, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s <ex://name> \"Galadriel\" .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s <ex://name> ?o .\n",
    "       filter (?o = \"Galadriel\")\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s the result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the match is case-sensitive and ignores the\n",
    "language-tagged literal in all cases. As usual [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements)\n",
    "matches only the exact kind of literal that we’ve provided, while\n",
    "SPARQL is more liberal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching a language-tagged string\n",
    "\n",
    "To retrieve the language-tagged variant we can ask for it explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://lang_g> <ex://name> \"Galadriel\"@sjn .\n",
      "\n",
      "SPARQL direct match\n",
      "-------------\n",
      "| s         |\n",
      "=============\n",
      "| ex:lang_g |\n",
      "-------------\n",
      "\n",
      "SPARQL filter match\n",
      "-----------------------------\n",
      "| s         | o             |\n",
      "=============================\n",
      "| ex:lang_g | Galadriel@sjn |\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, name, lang_g, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s <ex://name> \"Galadriel\"@sjn .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s <ex://name> ?o .\n",
    "       filter (?o = \"Galadriel\"@sjn)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly we get exactly what we have asked for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be wondering how to perform a string match where language and\n",
    "capitalization don’t matter. You can do that with a SPARQL filter\n",
    "query using the str() function, which strips out the string\n",
    "portion of a literal, leaving behind the datatype or language\n",
    "tag. Then the fn:lower-case() function eliminates case issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------\n",
      "| s          | o                                                |\n",
      "=================================================================\n",
      "| ex:lang_a  | Artanis@qya                                      |\n",
      "| ex:typed_a | Artanis^^http://www.w3.org/2001/XMLSchema#string |\n",
      "| ex:lower_a | artanis                                          |\n",
      "| ex:upper_a | Artanis                                          |\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s <ex://name> ?o .\n",
    "       filter (fn:lower-case(str(?o)) = \"artanis\")\n",
    "    }''',\n",
    "    output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query returns all variants of the selected literal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the SPARQL filter queries are powerful, but they are\n",
    "also the slowest queries. SPARQL direct queries and getStatements()\n",
    "queries are faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Booleans\n",
    "\n",
    "Boolean values in SPARQL are represented by literals of type\n",
    "<http://www.w3.org/2001/XMLSchema#boolean>. There are two ways to\n",
    "create such literals in Python:\n",
    "\n",
    "1. From corresponding Python boolean values (True and FAlse):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'franz.openrdf.model.literal.Literal'>\n",
      "<class 'franz.openrdf.model.literal.Literal'>\n"
     ]
    }
   ],
   "source": [
    "true1 = conn.createLiteral(True)\n",
    "false1 = conn.createLiteral(False)\n",
    "print(type(true1))\n",
    "print(type(false1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. By creating a typed literal with the value of \"true\" or\n",
    "\"false\". The type must be xsd:boolean:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "true2 = conn.createLiteral(\"true\", datatype=XMLSchema.BOOLEAN)\n",
    "false2 = conn.createLiteral(\"false\", datatype=XMLSchema.BOOLEAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Both ways of creating boolean literals produce equivalent results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"true\"^^<http://www.w3.org/2001/XMLSchema#boolean>\n",
      "\"true\"^^<http://www.w3.org/2001/XMLSchema#boolean>\n"
     ]
    }
   ],
   "source": [
    "print(true1)\n",
    "print(true2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the literals are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add some boolean data to the store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "    <ex://f> <ex://p>\n",
    "        \"false\"^^<http://www.w3.org/2001/XMLSchema#boolean> .\n",
    "    # In Turtle 'true' is the same as '\"true\"^^xsd:boolean\"'\n",
    "    <ex://t> <ex://p> true .\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When querying for boolean values using SPARQL one can use the literals\n",
    "true and false as a shorthand for\n",
    "\"true\"^^<http://www.w3.org/2001/XMLSchema#boolean> and\n",
    "\"false\"^^<http://www.w3.org/2001/XMLSchema#boolean>. The code\n",
    "below illustrates various ways of querying for boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://t> <ex://p> \"true\"^^<http://www.w3.org/2001/XMLSchema#boolean> .\n",
      "\n",
      "SPARQL direct match (true)\n",
      "--------\n",
      "| s    |\n",
      "========\n",
      "| ex:t |\n",
      "--------\n",
      "\n",
      "SPARQL direct match (\"false\"^^xsd:boolean)\n",
      "--------\n",
      "| s    |\n",
      "========\n",
      "| ex:f |\n",
      "--------\n",
      "\n",
      "SPARQL filter match (\"false\"^^xsd:boolean)\n",
      "----------------\n",
      "| s    | o     |\n",
      "================\n",
      "| ex:f | false |\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, None, true1, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match (true)')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s ?p true.}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match (\"false\"^^xsd:boolean)')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s ?p \"false\"^^xsd:boolean .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match (\"false\"^^xsd:boolean)')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"false\"^^xsd:boolean)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s the output from that script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates and times\n",
    "\n",
    "SPARQL represents dates and times using three literal types:\n",
    "xsd:date, xsd:time and xsd:dateTime. These can be created\n",
    "either explicitly from strings in the [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) format or from\n",
    "Python datetime.date, datetime.time and datetime.datetime\n",
    "values.\n",
    "\n",
    "Let’s create a few sample literals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, time, datetime\n",
    "import iso8601\n",
    "\n",
    "d = conn.createLiteral(date(1944, 8, 1))\n",
    "t = conn.createLiteral(time(15, 0, 0))\n",
    "dt = conn.createLiteral('1944-08-01T17:00:00+02:00',\n",
    "                        datatype=XMLSchema.DATETIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating time and datetime literals from Python values can\n",
    "yield somewhat unexpected results if time zones are involved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1944-08-01T17:00:00+02:00\"^^<http://www.w3.org/2001/XMLSchema#dateTime>\n",
      "\"1944-08-01T15:00:00Z\"^^<http://www.w3.org/2001/XMLSchema#dateTime>\n"
     ]
    }
   ],
   "source": [
    "surprise = conn.createLiteral(iso8601.parse_date(\n",
    "    '1944-08-01T17:00:00+02:00'))\n",
    "# Should be the same...\n",
    "print(dt)\n",
    "print(surprise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time has been converted to UTC. While both dt and surprise\n",
    "refer to the same moment in time, this conversion might still lead to\n",
    "problems if the user is not aware that it takes place.\n",
    "\n",
    "We will now add the newly created literals to the store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addTriple('<ex://d>', '<ex://p>', d)\n",
    "conn.addTriple('<ex://t>', '<ex://p>', t)\n",
    "conn.addTriple('<ex://dt>', '<ex://p>', dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections illustrate how date and time values behave\n",
    "during queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching dates\n",
    "\n",
    "Let’s try the usual mix of query methods and see what is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://d> <ex://p> \"1944-08-01\"^^<http://www.w3.org/2001/XMLSchema#date> .\n",
      "\n",
      "SPARQL direct match\n",
      "--------\n",
      "| s    |\n",
      "========\n",
      "| ex:d |\n",
      "--------\n",
      "\n",
      "SPARQL filter match\n",
      "---------------------\n",
      "| s    | o          |\n",
      "=====================\n",
      "| ex:d | 1944-08-01 |\n",
      "---------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, None, d, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s ?p \"1944-08-01\"^^xsd:date .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"1944-08-01\"^^xsd:date)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not surprising. It is worth noting that the datetime\n",
    "value has not been returned, even though it refers to the same date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching times\n",
    "\n",
    "Times can be queried in a similar fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://t> <ex://p> \"15:00:00Z\"^^<http://www.w3.org/2001/XMLSchema#time> .\n",
      "\n",
      "SPARQL direct match\n",
      "--------\n",
      "| s    |\n",
      "========\n",
      "| ex:t |\n",
      "--------\n",
      "\n",
      "SPARQL filter match\n",
      "--------------------\n",
      "| s    | o         |\n",
      "====================\n",
      "| ex:t | 15:00:00Z |\n",
      "--------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, None, t, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery(\n",
    "    'SELECT ?s WHERE {?s ?p \"15:00:00Z\"^^xsd:time .}',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"15:00:00Z\"^^xsd:time)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, only the value of the appropriate type is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching datetimes\n",
    "\n",
    "Datetimes work just like times and dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "<ex://dt> <ex://p> \"1944-08-01T17:00:00+02:00\"^^<http://www.w3.org/2001/XMLSchema#dateTime> .\n",
      "\n",
      "SPARQL direct match\n",
      "---------\n",
      "| s     |\n",
      "=========\n",
      "| ex:dt |\n",
      "---------\n",
      "\n",
      "SPARQL filter match\n",
      "-------------------------------------\n",
      "| s     | o                         |\n",
      "=====================================\n",
      "| ex:dt | 1944-08-01T17:00:00+02:00 |\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('getStatements():')\n",
    "conn.getStatements(None, None, dt, output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s WHERE {\n",
    "       ?s ?p \"1944-08-01T17:00:00+02:00\"^^xsd:dateTime .\n",
    "    }''',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"1944-08-01T17:00:00+02:00\"^^xsd:dateTime)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching datetimes with offsets\n",
    "\n",
    "We saw that times created from Python values are converted to UTC. So\n",
    "what happens when we query for Zulu time, while the value in the store\n",
    "is still in CEST? (An error is expected for the first query so we run that\n",
    "in a separate box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements():\n",
      "204 \n",
      "No response\n",
      "SPARQL direct match\n",
      "---------\n",
      "| s     |\n",
      "=========\n",
      "| ex:dt |\n",
      "---------\n",
      "\n",
      "SPARQL filter match\n",
      "-------------------------------------\n",
      "| s     | o                         |\n",
      "=====================================\n",
      "| ex:dt | 1944-08-01T17:00:00+02:00 |\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    zulu = conn.createLiteral(\"1944-08-01T15:00:00Z\",\n",
    "                          datatype=XMLSchema.DATETIME)\n",
    "    print('getStatements():')\n",
    "    conn.getStatements(None, None, zulu, output=True)\n",
    "    print()\n",
    "except:\n",
    "    print('No response')\n",
    "\n",
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s WHERE {\n",
    "       ?s ?p \"1944-08-01T15:00:00Z\"^^xsd:dateTime .\n",
    "    }''',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"1944-08-01T15:00:00Z\"^^xsd:dateTime)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARQL direct match\n",
      "---------\n",
      "| s     |\n",
      "=========\n",
      "| ex:dt |\n",
      "---------\n",
      "\n",
      "SPARQL filter match\n",
      "-------------------------------------\n",
      "| s     | o                         |\n",
      "=====================================\n",
      "| ex:dt | 1944-08-01T17:00:00+02:00 |\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('SPARQL direct match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s WHERE {\n",
    "       ?s ?p \"1944-08-01T15:00:00Z\"^^xsd:dateTime .\n",
    "    }''',\n",
    "    output=True)\n",
    "print()\n",
    "\n",
    "print('SPARQL filter match')\n",
    "conn.executeTupleQuery('''\n",
    "    SELECT ?s ?o WHERE {\n",
    "       ?s ?p ?o .\n",
    "       filter (?o = \"1944-08-01T15:00:00Z\"^^xsd:dateTime)\n",
    "    }''',\n",
    "    output=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AllegroGraph still finds our value when using SPARQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating SPARQL queries AllegroGraph treats datetime\n",
    "objects that refer to the same point in time as equivalent, regardless\n",
    "of the timezone used in their representation. [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements)\n",
    "performs exact matching, so will not return a value with different\n",
    "timezone.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6: Importing triples\n",
    "\n",
    "AllegroGraph can import files in multiple RDF [formats](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.rio.html#franz.openrdf.rio.rdfformat.RDFFormat), such as [Turtle](https://www.w3.org/TR/turtle/) or [N-Triples](https://www.w3.org/TR/n-triples/). The example below\n",
    "calls the connection object’s [add()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.add) method to load an N-Triples\n",
    "file, and [addFile()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addFile) to load an RDF/XML file. Both methods work,\n",
    "but the best practice is to use [addFile()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addFile).\n",
    "\n",
    "The RDF/XML file contains a short\n",
    "list of v-cards (virtual business cards), like this one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this file in ./data/vcards.rdf (or choose another path\n",
    "and adjust the code below).\n",
    "\n",
    "The N-Triples file contains\n",
    "a graph of resources describing the Kennedy family, the places where\n",
    "they were each born, their colleges, and their professions. A typical\n",
    "entry from that file looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the file to ./data/kennedy.ntriples.\n",
    "\n",
    "Note that AllegroGraph can segregate triples into contexts (subgraphs)\n",
    "by treating them as quads, but the N-Triples and RDF/XML formats\n",
    "cannot include context information (unlike e.g [N-Quads](https://www.w3.org/TR/n-quads/) or\n",
    "[Trig](https://www.w3.org/TR/trig/)). They deal with triples only, so there is no place to store a\n",
    "fourth field in those formats. In the case of the [add()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.add) call, we\n",
    "have omitted the context argument so the triples are loaded into the\n",
    "default graph (sometimes called the “null context.”) The\n",
    "[addFile()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addFile) call includes an explicit context setting, so the\n",
    "fourth field of each VCard triple will be the context named\n",
    "http://example.org#vcards. The connection [size()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.size) method\n",
    "takes an optional context argument. With no argument, it returns the\n",
    "total number of triples in the repository. Below, it returns the\n",
    "number 16 for the context context argument, and the number\n",
    "28 for the null context (None) argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables path1 and path2 are bound to the RDF/XML and\n",
    "N-Triples files, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "# We assume that our data files live in this directory.\n",
    "DATA_DIR = 'data'\n",
    "path1 = os.path.join(DATA_DIR, 'vcards.rdf')\n",
    "path2 = os.path.join(DATA_DIR, 'kennedy.ntriples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The triples about the VCards will be added to a specific context, so\n",
    "naturally we need a URI to identify that context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = conn.createURI(\"http://example.org#vcards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we use [addFile()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addFile) to load the VCard triples into\n",
    "the #vcards context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.rio.rdfformat import RDFFormat\n",
    "\n",
    "conn.addFile(path1, None, format=RDFFormat.RDFXML, context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use [add()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.add) to load the Kennedy family tree into the\n",
    "default context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.add(path2, base=None, format=RDFFormat.NTRIPLES, contexts=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll ask AllegroGraph to report on how many triples it sees in\n",
    "the default context and in the #vcards context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCard triples (in <http://example.org#vcards>): 16\n",
      "Kennedy triples (default graph): 1214\n"
     ]
    }
   ],
   "source": [
    "print('VCard triples (in {context}): {count}'.format(\n",
    "      count=conn.size(context), context=context))\n",
    "\n",
    "print('Kennedy triples (default graph): {count}'.format(\n",
    "      count=conn.size('null')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7: Querying multiple contexts\n",
    "\n",
    "The purpose of this example is to see how data imported into multiple\n",
    "contexts (like that from [Example 6: Importing triples](#example6)) behaves when queried using\n",
    "various methods. This exampe covers only the results of basic\n",
    "queries. The subject is explored in more detail in [Example 10: Graphs in SPARQL](#example10).\n",
    "\n",
    "Let us start by creating a connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and adding a few triples in the default context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.query.query import QueryLanguage\n",
    "\n",
    "conn.addData(\"\"\"\n",
    "   <ex://default1> <ex://p1> 1 .\n",
    "   <ex://default2> <ex://p2> 2 .\n",
    "   <ex://default3> <ex://p3> 3 .\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add data to another contect by using the optional context\n",
    "parameter of [addData()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addData):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = conn.createURI('ex://context')\n",
    "conn.addData(\"\"\"\n",
    "   <ex://context1> <ex://p1> 1 .\n",
    "   <ex://context2> <ex://p2> 2 .\n",
    "   <ex://context3> <ex://p3> 3 .\"\"\",\n",
    "   context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try a [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) call first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://context1>\n",
      "<ex://default1>\n"
     ]
    }
   ],
   "source": [
    "p1 = conn.createURI('ex://p1')\n",
    "with conn.getStatements(None, p1, None, None) as result:\n",
    "    for row in result:\n",
    "        print(row.getSubject())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop prints out a mix of triples from the default context and\n",
    "from the named context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPARQL queries behave in a different way. When a graph clause is\n",
    "present, as in the following code, triples that are not in a named\n",
    "context will not be examined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://context3>\n"
     ]
    }
   ],
   "source": [
    "query_string = \"\"\"\n",
    "    SELECT DISTINCT ?s WHERE {\n",
    "      graph ?g { ?s ?p ?o filter(?o > 2).\n",
    "    }} order by ?s\"\"\"\n",
    "tuple_query = conn.prepareTupleQuery(\n",
    "    QueryLanguage.SPARQL, query_string)\n",
    "with tuple_query.evaluate() as result:\n",
    "    for bindings in result:\n",
    "        print(bindings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the context3 triple is printed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we issue a trivial query without mentioning graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://context1>\n",
      "<ex://context2>\n",
      "<ex://context3>\n",
      "<ex://default1>\n",
      "<ex://default2>\n",
      "<ex://default3>\n"
     ]
    }
   ],
   "source": [
    "query_string = \"\"\"\n",
    "    SELECT DISTINCT ?s WHERE {\n",
    "      ?s ?p ?o .\n",
    "    } order by ?s\"\"\"\n",
    "tuple_query = conn.prepareTupleQuery(\n",
    "    QueryLanguage.SPARQL, query_string)\n",
    "with tuple_query.evaluate() as result:\n",
    "    for bindings in result:\n",
    "        print(bindings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints all triples, just like a [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this behavior can be altered by setting a query option.\n",
    "AllegroGraph allows such options to be set by defining\n",
    "a prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://default1>\n",
      "<ex://default2>\n",
      "<ex://default3>\n"
     ]
    }
   ],
   "source": [
    "query_string = \"\"\"\n",
    "    PREFIX franzOption_defaultDatasetBehavior: <franz:rdf>\n",
    "    SELECT DISTINCT ?s WHERE {\n",
    "      ?s ?p ?o .\n",
    "    } order by ?s\"\"\"\n",
    "tuple_query = conn.prepareTupleQuery(\n",
    "    QueryLanguage.SPARQL, query_string)\n",
    "with tuple_query.evaluate() as result:\n",
    "    for bindings in result:\n",
    "        print(bindings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now only the default context is matched by simple pattern (i.e. ones\n",
    "not wrapped in graph ?g { ... })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 8: Exporting triples\n",
    "\n",
    "This example shows how to serialize contents of a repository to a\n",
    "file. As usual we’ll start with obtaining a connection to the\n",
    "repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s import some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "  <ex://s> <ex://p1> <ex://o1> , <ex://o2> ;\n",
    "           <ex://p2> <ex://o3> .\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be exported by passing a file name or a file-like object as\n",
    "the output parameter of [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements). In this case we’ll\n",
    "want to print all statements to standard output. We can do this by\n",
    "passign True as the output file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://s> <ex://p2> <ex://o3> .\n",
      "<ex://s> <ex://p1> <ex://o2> .\n",
      "<ex://s> <ex://p1> <ex://o1> .\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.rio.rdfformat import RDFFormat\n",
    "\n",
    "conn.getStatements(output=True, output_format=RDFFormat.NTRIPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that results are printed in the specified format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use other arguments of [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) to constrain\n",
    "the set of exported tripes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://s> <ex://p1> <ex://o1> .\n",
      "<ex://s> <ex://p1> <ex://o2> .\n"
     ]
    }
   ],
   "source": [
    "conn.getStatements(None, conn.createURI('ex://p1'), None,\n",
    "                   output=True,\n",
    "                   output_format=RDFFormat.NTRIPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the result contains only two triples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file path can also be passed as the output argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://s> <ex://p2> <ex://o3> .\n",
      "<ex://s> <ex://p1> <ex://o2> .\n",
      "<ex://s> <ex://p1> <ex://o1> .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "conn.getStatements(output='example8.nt')\n",
    "with open('example8.nt', 'r') as f:\n",
    "    sys.stdout.write(f.read())\n",
    "\n",
    "os.remove('example8.nt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs data read from the file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example9'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 9: Exporting query results\n",
    "\n",
    "The [previous example](#example8) showed how to serialize\n",
    "statements to a file or a stream. It is also possible to perform a\n",
    "similar operation on the result of a query.\n",
    "\n",
    "As usual, we’ll start by opening a connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and importing sample data - in this case containing birth and\n",
    "(when applicable) coronation dates of the sons of Henry II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "  @prefix : <ex://> .\n",
    "  @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "  :Henry :born \"1155-02-28\"^^xsd:date .\n",
    "  :Richard :born \"1157-09-08\"^^xsd:date .\n",
    "  :Geoffrey :born \"1158-09-23\"^^xsd:date .\n",
    "  :John :born \"1166-12-24\"^^xsd:date .\n",
    "\n",
    "  :Henry :crowned \"1170-06-14\"^^xsd:date .  # sort of...\n",
    "  :Richard :crowned \"1189-09-03\"^^xsd:date .\n",
    "  :John :crowned \"1199-05-27\"^^xsd:date .\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query results can be exported by passing a file name or a file-like\n",
    "object as the output parameter of the [TupleQuery.evaluate()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.query.TupleQuery.evaluate)\n",
    "method of the query object. In this case we’ll want to print all kings\n",
    "born in or after 1156 from our dataset to standard output (we can use\n",
    "True as the file name to indicate stdout):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name,crowned\n",
      "\"ex://Richard\",\"1189-09-03\"\n",
      "\"ex://John\",\"1199-05-27\"\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.query.query import QueryLanguage\n",
    "from franz.openrdf.rio.tupleformat import TupleFormat\n",
    "\n",
    "query = conn.prepareTupleQuery(\n",
    "    QueryLanguage.SPARQL,\n",
    "    \"\"\"\n",
    "    select ?name ?crowned {\n",
    "       ?name <ex://born> ?birth .\n",
    "       ?name <ex://crowned> ?crowned .\n",
    "       filter(?birth >= \"1156-01-01\"^^xsd:date) .\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True,\n",
    "               output_format=TupleFormat.CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that results are printed in the specified format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can export the result of a CREATE or DESCRIBE query in a\n",
    "similar fashion. The difference is that we need to supply an\n",
    "[RDFFormat](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.rio.html#franz.openrdf.rio.rdfformat.RDFFormat) instead of a [TupleFormat](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.rio.html#franz.openrdf.rio.tupleformat.TupleFormat), since the\n",
    "result is a set of triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dc: <http://purl.org/dc/elements/1.1/> .\n",
      "@prefix dcterms: <http://purl.org/dc/terms/> .\n",
      "@prefix err: <http://www.w3.org/2005/xqt-errors#> .\n",
      "@prefix fn: <http://www.w3.org/2005/xpath-functions#> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix fti: <http://franz.com/ns/allegrograph/2.2/textindex/> .\n",
      "@prefix keyword: <http://franz.com/ns/keyword#> .\n",
      "@prefix nd: <http://franz.com/ns/allegrograph/5.0/geo/nd#> .\n",
      "@prefix ndfn: <http://franz.com/ns/allegrograph/5.0/geo/nd/fn#> .\n",
      "@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
      "@prefix xs: <http://www.w3.org/2001/XMLSchema#> .\n",
      "<ex://Richard> <ex://born> \"1157-09-08\"^^xs:date ; \n",
      "  <ex://crowned> \"1189-09-03\"^^xs:date . \n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.rio.rdfformat import RDFFormat\n",
    "\n",
    "query = conn.prepareGraphQuery(\n",
    "    QueryLanguage.SPARQL, \"describe <ex://Richard> where {}\")\n",
    "query.evaluate(output=True,\n",
    "               output_format=RDFFormat.TURTLE) # NTRIPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the result contains two triples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file path can also be passed as the output argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name,birth,coronation\n",
      "\"ex://Henry\",\"1155-02-28\",\"1170-06-14\"\n",
      "\"ex://Richard\",\"1157-09-08\",\"1189-09-03\"\n",
      "\"ex://John\",\"1166-12-24\",\"1199-05-27\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "query = conn.prepareTupleQuery(\n",
    "    QueryLanguage.SPARQL,\n",
    "    \"\"\"\n",
    "    select ?name ?birth ?coronation {\n",
    "      ?name <ex://born> ?birth ;\n",
    "            <ex://crowned> ?coronation .\n",
    "    }\"\"\")\n",
    "query.evaluate(output='example9.csv',\n",
    "               output_format=TupleFormat.CSV)\n",
    "with open('example9.csv', 'r') as f:\n",
    "    sys.stdout.write(f.read())\n",
    "\n",
    "os.remove('example9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This outputs data read from the file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example10'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 10: Graphs in SPARQL\n",
    "\n",
    "In [Example 6: Importing triples](#example6) and [Example 7: Querying multiple contexts](#example7) we’ve seen how to import data\n",
    "to a non-default context and run queries against such data. In this\n",
    "example we’ll explore facilities for handling multiple contexts\n",
    "provided by SPARQL and the AllegroGraph Python client.\n",
    "\n",
    "We’ll start by opening a connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create two URIs that will represent named contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "context1 = conn.createURI(\"ex://context1\")\n",
    "context2 = conn.createURI(\"ex://context2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first context will be filled using the [addData()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addData) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "    @prefix : <ex://> .\n",
    "    :alice a :person ;\n",
    "           :name \"Alice\" .\"\"\",\n",
    "    context=context1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second context will be filled using [addTriple()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addTriple). Notice how\n",
    "we use a constant defined in the RDF class to obtain the URI of\n",
    "the type predicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.vocabulary.rdf import RDF\n",
    "\n",
    "bob = conn.createURI('ex://bob')\n",
    "bob_name = conn.createLiteral('Bob')\n",
    "name = conn.createURI('ex://person')\n",
    "person = conn.createURI('ex://person')\n",
    "conn.addTriple(bob, RDF.TYPE, person,\n",
    "               contexts=[context2])\n",
    "conn.addTriple(bob, name, bob_name,\n",
    "               contexts=[context2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we’ll add two triples to the default context using\n",
    "[addStatement()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addStatement):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.model import Statement\n",
    "\n",
    "ted = conn.createURI('ex://ted')\n",
    "ted_name = conn.createLiteral('Ted')\n",
    "stmt1 = Statement(ted, name, ted_name)\n",
    "stmt2 = Statement(ted, RDF.TYPE, person)\n",
    "conn.addStatement(stmt1)\n",
    "conn.addStatement(stmt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Statement](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.model.html#franz.openrdf.model.Statement) object contains a context field.\n",
    "This field is *ignored* by [addStatement()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addStatement). If you\n",
    "wish to add a statement object to a specific context, use\n",
    "the contexts parameter.\n",
    "\n",
    "As we’ve seen already in [Example 7: Querying multiple contexts](#example7), a call to\n",
    "[getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) will return triples from all contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements(): 6\n",
      "size(): 6\n"
     ]
    }
   ],
   "source": [
    "with conn.getStatements() as result:\n",
    "    print('getStatements(): {0}'.format(len(result)))\n",
    "print('size(): {0}'.format(conn.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[size()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.size) will also process all contexts by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) and [size()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.size) accept a contexts\n",
    "parameter that can be used to limit processing to a specified list of\n",
    "graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements(): 4\n",
      "size(): 4\n"
     ]
    }
   ],
   "source": [
    "contexts = [context1, context2]\n",
    "with conn.getStatements(contexts=contexts) as result:\n",
    "    print('getStatements(): {0}'.format(len(result)))\n",
    "print('size(): {0}'.format(conn.size(contexts=contexts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, triples from the default context are not processed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To include the default graph when using the contexts parameter use\n",
    "None as a graph URI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getStatements(): 4\n",
      "size(): 4\n"
     ]
    }
   ],
   "source": [
    "contexts = [context1, None]\n",
    "with conn.getStatements(contexts=contexts) as result:\n",
    "    print('getStatements(): {0}'.format(len(result)))\n",
    "print('size(): {0}'.format(conn.size(contexts=contexts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now triples from the default context and from one of our named\n",
    "contexts are processed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARQL using FROM, FROM DEFAULT, and FROM NAMED\n",
    "\n",
    "In many of our examples we have used a simple SPARQL query to retrieve\n",
    "triples from AllegroGraph’s default graph. This has been very\n",
    "convenient but it is also misleading. As soon as we tell SPARQL to\n",
    "search a specific graph, we lose the ability to search AllegroGraph’s\n",
    "default graph! Triples from the null graph vanish from the search\n",
    "results. Why is that?\n",
    "\n",
    "It is important to understand that AllegroGraph and SPARQL use the\n",
    "phrase “default graph” to identify two very different\n",
    "things.\n",
    "\n",
    "- AllegroGraph’s default graph, or null context, is simply the set\n",
    "  of all triples that have null in the fourth field of the\n",
    "  “triple.” The *default graph* is an unnamed subgraph of the\n",
    "  AllegroGraph triple store.  \n",
    "  - SPARQL uses *default graph* to describe something that is very\n",
    "  different. In SPARQL, the *default graph* is a temporary pool of\n",
    "  triples imported from one or more *named* graphs. SPARQL’s\n",
    "  *default graph* is constructed and discarded in the service of a\n",
    "  single query.  Standard SPARQL was designed for named graphs\n",
    "  only, and has no syntax to identify a truly unnamed\n",
    "  graph. AllegroGraph’s SPARQL, however, has been extended to allow\n",
    "  the unnamed graph to participate in multi-graph queries.  \n",
    "  \n",
    "\n",
    "We can use AllegroGraph’s SPARQL to search specific subgraphs in three\n",
    "ways.\n",
    "\n",
    "- We can create a temporary *default graph* using the FROM\n",
    "  operator.  \n",
    "  - We can put AllegroGraph’s unnamed graph into SPARQL’s default\n",
    "  graph using FROM DEFAULT.  \n",
    "  - Or we can target specific named graphs using the FROM NAMED\n",
    "  operator.  \n",
    "  \n",
    "\n",
    "Here’s an example of a query that accesses the unnamed graph explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "| s        |\n",
      "============\n",
      "| ex://ted |\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT DISTINCT ?s FROM DEFAULT {\n",
    "        ?s ?p ?o\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will not process any of the triples in named contexts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s an example of a query that uses FROM. It instructs SPARQL\n",
    "to regard context1 as the default graph for the purposes of this\n",
    "query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "| s          |\n",
      "==============\n",
      "| ex://alice |\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT DISTINCT ?s FROM <ex://context1> {\n",
    "        ?s ?p ?o\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now only one context is processed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example changes FROM to FROM NAMED in the same query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "| s |\n",
      "=====\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT DISTINCT ?s FROM NAMED <ex://context1> {\n",
    "        ?s ?p ?o\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no matches now! The pattern { ?s ?p ?o . } only matches\n",
    "the SPARQL default graph. We declared context1 to be a *named*\n",
    "graph, so it is no longer the default graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To match triples in named graphs, SPARQL requires a GRAPH pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| s          | g             |\n",
      "==============================\n",
      "| ex://alice | ex://context1 |\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT DISTINCT ?s ?g FROM NAMED <ex://context1> {\n",
    "        GRAPH ?g { ?s ?p ?o }\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we’ll also print the graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine all the forms presented above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| s          | g             |\n",
      "==============================\n",
      "| ex://ted   | ---           |\n",
      "| ex://alice | ---           |\n",
      "| ex://bob   | ex://context2 |\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT DISTINCT ?s ?g\n",
    "    FROM DEFAULT\n",
    "    FROM <ex://context1>\n",
    "    FROM NAMED <ex://context2> {\n",
    "        { ?s ?p ?o } UNION { GRAPH ?g { ?s ?p ?o } }\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query puts AllegroGraph’s unnamed graph and the context1\n",
    "graph into SPARQL’s default graph, where the triples can be found by\n",
    "using a simple {?s ?p ?o . } query.  Then it identifies\n",
    "context2 as a named graph, which can be searched using a GRAPH\n",
    "pattern.  In the final line, we used a UNION operator to combine\n",
    "the matches of the simple and GRAPH patterns.\n",
    "\n",
    "This query should find all three subjects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPARQL with [Dataset](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.dataset.Dataset) object\n",
    "\n",
    "A [Dataset](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.dataset.Dataset) object is a construct that contains two lists of\n",
    "named graphs. There is one list of graphs that will become the SPARQL\n",
    "default graph, just like using FROM in the query. There is a\n",
    "second list of graphs that will be *named graphs* in the query, just\n",
    "like using FROM NAMED. To use the dataset, we put the graph URIs into\n",
    "the dataset object, and then add the dataset to the query object. When\n",
    "we evaluate the query, the results will be confined to the graphs\n",
    "listed in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| s          | g             |\n",
      "==============================\n",
      "| ex://alice | ---           |\n",
      "| ex://bob   | ex://context2 |\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.query.dataset import Dataset\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.addDefaultGraph(context1)\n",
    "dataset.addNamedGraph(context2)\n",
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT DISTINCT ?s ?g {\n",
    "      { ?s ?p ?o } UNION { GRAPH ?g { ?s ?p ?o } }\n",
    "    }\"\"\")\n",
    "query.setDataset(dataset)\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, since we’re explicitly specifying graphs (through a dataset\n",
    "object), we need a GRAPH pattern to match triples from the named\n",
    "graphs. Triples from the unnamed graph are not matched at all, since\n",
    "that graph is not a part of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example11'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 11: Namespaces\n",
    "\n",
    "A *namespace* is that portion of a URI that preceeds the last #,\n",
    "/, or : character, inclusive. The remainder of a URI is called\n",
    "the localname. For example, with respect to the URI\n",
    "http://example.org/people/alice, the namespace is\n",
    "http://example.org/people/ and the localname is alice. When\n",
    "writing SPARQL queries, it is convenient to define prefixes or\n",
    "nicknames for the namespaces, so that abbreviated URIs can be\n",
    "specified. For example, if we define ex to be a nickname for\n",
    "http://example.org/people/, then the string ex:alice is a\n",
    "recognized abbreviation for http://example.org/people/alice. This\n",
    "abbreviation is called a *qname* (qualified name).\n",
    "\n",
    "In the SPARQL query discussed in this chapter we see two qnames,\n",
    "rdf:type and ex:alice. Ordinarily, we would expect to see\n",
    "PREFIX declarations in SPARQL that define namespaces for the\n",
    "rdf and ex nicknames. However, the connection and query\n",
    "machinery can do that job for you. The mapping of prefixes to\n",
    "namespaces includes the built-in prefixes rdf, rdfs, xsd,\n",
    "and owl. Hence, we can write rdf:type in a SPARQL query, and\n",
    "the system already knows its meaning. In the case of the ex\n",
    "prefix, we need to instruct it. The [setNamespace()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.setNamespace) method of the\n",
    "connection object registers a new namespace.\n",
    "\n",
    "It is legal, although not recommended, to redefine the\n",
    "built-in prefixes (RDF, XSD etc…).\n",
    "\n",
    "We start by opening a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and creating two URIs. Note how [createURI()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.createURI) allows us to compose\n",
    "URIs from namespaces and local names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "exns = \"http://example.org/people/\"\n",
    "alice = conn.createURI(namespace=exns, localname=\"alice\")\n",
    "person = conn.createURI(namespace=exns, localname=\"Person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can assert Alice’s RDF:TYPE triple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.vocabulary.rdf import RDF\n",
    "\n",
    "conn.add(alice, RDF.TYPE, person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we register the exns namespace with the connection object, so\n",
    "we can use it in a SPARQL query. The query looks for triples that have\n",
    "rdf:type in the predicate position, and ex:Person in the\n",
    "object position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| s        | p        | o         |\n",
      "===================================\n",
      "| ex:alice | rdf:type | ex:Person |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "conn.setNamespace('ex', exns)\n",
    "conn.executeTupleQuery(\"\"\"\n",
    "    SELECT ?s ?p ?o WHERE {\n",
    "        ?s ?p ?o .\n",
    "        FILTER (?p = rdf:type && ?o = ex:Person)\n",
    "    }\"\"\", output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output shows the single triple that we expected to find. This\n",
    "demonstrates that the qnames in the SPARQL query successfully matched\n",
    "the fully-expanded URIs in the triple. Note that the namespace prefix\n",
    "is also used in the table below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be mentioned here that the prefix of a namespace can be an\n",
    "empty string. This allows the resulting qnames to be very concise and\n",
    "readable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "| s     |\n",
      "=========\n",
      "| :this |\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "conn.setNamespace('', 'http://a-long-and-often-used-namespace/')\n",
    "conn.executeUpdate('insert data { :this :looks :nice }')\n",
    "conn.executeTupleQuery('select ?s { ?s :looks :nice }',\n",
    "                       output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example12'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 12: Free Text indexing\n",
    "\n",
    "It is common for users to build RDF applications that combine some\n",
    "form of “keyword search” with their queries. For example, a user might\n",
    "want to retrieve all triples for which the string “Alice” appears as a\n",
    "word within the third (object) field of the triple. AllegroGraph\n",
    "provides a capability for including free text matching within a SPARQL\n",
    "query, and also by using the [evalFreeTextSearch()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.evalFreeTextSearch) method of the\n",
    "connection object. It requires, however, that you create and configure\n",
    "indexes appropriate to the searches you want to pursue.\n",
    "\n",
    "First let’s open a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start this example by importing some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "    @prefix : <ex://> .\n",
    "\n",
    "    :alice a :Person ;\n",
    "             :fullname \"Alice B. Toklas\" .\n",
    "    :book1 a :Book ;\n",
    "             :title \"Alice in Wonderland\" ;\n",
    "             :author :carroll .\n",
    "\n",
    "    :carroll a :Person ;\n",
    "               :fullname \"Lewis Carroll\" .\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create an index. AllegroGraph lets you create any number of\n",
    "text indexes, each for a specific purpose. In this case we are\n",
    "indexing the literal values we find in the fullname predicate,\n",
    "which we have used in resources that describe people. The\n",
    "[createFreeTextIndex()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.createFreeTextIndex) method has many configurable\n",
    "parameters. Their default settings are appropriate to this\n",
    "situation. All we have to provide is a name for the index and the URI\n",
    "of the predicate (or predicates) that contain the text to be indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullname = conn.createURI(namespace='ex://',\n",
    "                         localname='fullname')\n",
    "conn.createFreeTextIndex(\n",
    "    \"index1\", predicates=[fullname])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the index configuration using the\n",
    "[getFreeTextIndexConfiguration()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getFreeTextIndexConfiguration) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicates: [<ex://fullname>]\n",
      "indexLiterals: True\n",
      "indexResources: False\n",
      "indexFields: ['object']\n",
      "minimumWordSize: 3\n",
      "stopWords: ['and', 'are', 'but', 'for', 'into', 'not', 'such', 'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'was', 'will', 'with']\n",
      "wordFilters: []\n",
      "innerChars: []\n",
      "borderChars: []\n",
      "tokenizer: default\n"
     ]
    }
   ],
   "source": [
    "config = conn.getFreeTextIndexConfiguration(\"index1\")\n",
    "for key, value in config.items():\n",
    "    print('{key}: {value}'.format(key=key, value=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This configuration says that index1 will operate on the literal\n",
    "values it finds in the object position of the <ex://fullname>\n",
    "predicate. It ignores words smaller than three characters in\n",
    "length. It will ignore the words in its stopWords list (elided\n",
    "from sample output). If it encounters a resource URI in the object\n",
    "position, it will ignore it. This index doesn’t use any\n",
    "wordFilters, which are sometimes used to remove accented letters\n",
    "and to perform stemming on indexed text and search strings.\n",
    "\n",
    "The text match occurs through a “magic” predicate called fti:match.\n",
    "This predicate has two arguments. One is the subject URI of the\n",
    "resources to search. The other is the string pattern to search for,\n",
    "such as “Alice”. Only full-word matches will be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "| s          |\n",
      "==============\n",
      "| ex://alice |\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT ?s WHERE {\n",
    "        ?s fti:match \"Alice\" .\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to include a prefix declaration for the fti\n",
    "namespace. That is because fti is included among the built-in\n",
    "namespace mappings in AllegroGraph.\n",
    "\n",
    "When we execute our SPARQL query, it matches the \"Alice\" within the literal \"Alice B. Toklas\" because that literal occurs in a triple having the fullname predicate, but it does not match the “Alice” in the literal \"Alice in Wonderland\" because the title predicate was not included in our index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default fti:match searches in all text indexes. It is possible\n",
    "to specify a single index name when searching. We’ll illustrate this\n",
    "be creating another index, this time on the title predicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "| s          |\n",
      "==============\n",
      "| ex://book1 |\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "title = conn.createURI(namespace='ex://',\n",
    "                       localname='title')\n",
    "conn.createFreeTextIndex(\n",
    "    \"index2\", predicates=[title])\n",
    "\n",
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT ?s WHERE {\n",
    "        ?s fti:match ( \"Alice\" \"index2\" ) .\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time only the book title will match our query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of searching text indexes is the\n",
    "[evalFreeTextSearch()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.evalFreeTextSearch) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://alice>\n"
     ]
    }
   ],
   "source": [
    "for triple in conn.evalFreeTextSearch(\n",
    "        \"Alice\", index=\"index1\"):\n",
    "    print(triple[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works just like our first query. Note that\n",
    "[evalFreeTextSearch()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.evalFreeTextSearch) returns a list of lists of strings (in\n",
    "N-Triples format), not a list of [Statement](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.model.html#franz.openrdf.model.Statement) objects.\n",
    "\n",
    "Yay for consistency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text index supports simple wildcard queries. The asterisk (*)\n",
    "may be appended to the end of the pattern to indicate “any number of\n",
    "additional characters.” For instance, this query looks for whole words\n",
    "that begin with “Ali”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://book1>\n",
      "<ex://alice>\n"
     ]
    }
   ],
   "source": [
    "for triple in conn.evalFreeTextSearch(\"Ali*\"):\n",
    "    print(triple[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This search runs across both indexes, so it will find both the\n",
    ":title and the :fullname triples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a single-character wildcard, the question mark. It will\n",
    "match any single character. You can add as many question marks as you\n",
    "need to the string pattern. This query looks for a five-letter word\n",
    "that has “l” in the second position, and “c” in the fourth position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://book1>\n",
      "<ex://alice>\n"
     ]
    }
   ],
   "source": [
    "for triple in conn.evalFreeTextSearch(\"?l?c?*\"):\n",
    "    print(triple[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the same as for the previous query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text indexes are not the only way of matching text values available in\n",
    "SPARQL. One may also filter results using regular expressions. This\n",
    "approach is more flexible, but at the price of performance. Regular\n",
    "expression filters do not use any form of indexing to speed up the\n",
    "query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "| s            | p             | o                   |\n",
      "======================================================\n",
      "| ex://alice   | ex://fullname | Alice B. Toklas     |\n",
      "| ex://book1   | ex://title    | Alice in Wonderland |\n",
      "| ex://carroll | ex://fullname | Lewis Carroll       |\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT ?s ?p ?o WHERE {\n",
    "        ?s ?p ?o .\n",
    "        FILTER regex(?o, \"lic|oll\")\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how this search matches the provided pattern inside words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to indexing literal values, AllegroGraph can also index\n",
    "resource URIs. index3 is an index that looks for URIs in the\n",
    "object position of the author predicate, and then indexes only the\n",
    "local name of the resource (the characters following the rightmost\n",
    "/, # or : in the URI). This lets us avoid indexing\n",
    "highly-repetitive namespace strings, which would fill the index with\n",
    "data that would not be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://book1>\n"
     ]
    }
   ],
   "source": [
    "author = conn.createURI(namespace='ex://',\n",
    "                        localname='author')\n",
    "\n",
    "conn.createFreeTextIndex(\n",
    "    \"index3\", predicates=[author],\n",
    "    indexResources=\"short\", indexFields=[\"object\"])\n",
    "\n",
    "for triple in conn.evalFreeTextSearch(\"carroll\",\n",
    "                                      index=\"index3\"):\n",
    "    print(triple[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text search located the triple that has carroll in the URI in\n",
    "the object position:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example13'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 13: SPARQL query forms\n",
    "\n",
    "SPARQL provides alternatives to the standard SELECT query. This\n",
    "example exercises these alternatives to show how AllegroGraph Server\n",
    "and the Python client handle them.\n",
    "\n",
    "Let’s connect to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll need some sample data to illustrate all the query types. Our\n",
    "dataset will contain information about rulers of 17th century England."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "    @prefix : <ex://> .\n",
    "    @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "    :james_i :reigned_from \"1603-03-24\"^^xsd:date ;\n",
    "             :reigned_to \"1625-03-27\"^^xsd:date .\n",
    "    :charles_i :reigned_from \"1625-03-27\"^^xsd:date ;\n",
    "               :reigned_to \"1649-01-30\"^^xsd:date ;\n",
    "               :child_of :james_i .\n",
    "    :charles_ii :reigned_from \"1649-01-30\"^^xsd:date ;\n",
    "             :reigned_to \"1685-02-06\"^^xsd:date ;\n",
    "             :child_of :charles_i .\n",
    "    :james_ii :reigned_from \"1685-02-06\"^^xsd:date ;\n",
    "             :reigned_to \"1688-12-11\"^^xsd:date ;\n",
    "             :child_of :charles_i .\n",
    "    :mary_ii :reigned_from \"1689-02-13\"^^xsd:date ;\n",
    "             :reigned_to \"1694-12-28\"^^xsd:date ;\n",
    "             :child_of :james_ii .\n",
    "    :william_iii :reigned_from \"1672-07-04\"^^xsd:date ;\n",
    "                 :reigned_to \"1702-03-08\"^^xsd:date .\n",
    "    :anne :reigned_from \"1707-05-01\"^^xsd:date ;\n",
    "          :reigned_to \"1714-08-01\"^^xsd:date ;\n",
    "          :child_of :james_ii .\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT\n",
    "\n",
    "This kind of query returns a sequence of tuples, binding variables to\n",
    "matching elements of a search pattern. SELECT queries are created\n",
    "using [prepareTupleQuery()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.prepareTupleQuery) and return results of type\n",
    "[TupleQueryResult](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.queryresult.TupleQueryResult). Query result can also be serialized in a\n",
    "supported [TupleFormat](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.rio.html#franz.openrdf.rio.tupleformat.TupleFormat) - in previous examples we used\n",
    "output=True and relied on the default TupleFormat.TABLE.\n",
    "\n",
    "Here’s a sample query which locates all rulers whose grandchildren\n",
    "inherited the crown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://charles_i>\n",
      "<ex://james_i>\n"
     ]
    }
   ],
   "source": [
    "conn.setNamespace('', 'ex://')\n",
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT DISTINCT ?name WHERE {\n",
    "        ?grandchild :child_of/:child_of ?name .\n",
    "    } ORDER BY ?name \"\"\")\n",
    "\n",
    "with query.evaluate() as result:\n",
    "    for bindings in result:\n",
    "        print(bindings.getValue('name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two names are returned:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also serialize the output instead of processing the result\n",
    "object. This time let us reverse the query and ask for rulers whose\n",
    "grandparents are also in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "\"ex://anne\"\n",
      "\"ex://charles_ii\"\n",
      "\"ex://james_ii\"\n",
      "\"ex://mary_ii\"\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.rio.tupleformat import TupleFormat\n",
    "\n",
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "   SELECT DISTINCT ?name WHERE {\n",
    "      ?name :child_of/:child_of ?grandparent .\n",
    "   } ORDER BY ?name \"\"\")\n",
    "\n",
    "query.evaluate(output=True, output_format=TupleFormat.CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get four results, serialized as CSV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASK\n",
    "\n",
    "The ASK query returns a Boolean, depending on whether the triple\n",
    "pattern matched any triples. Queries of this type are created using\n",
    "[prepareBooleanQuery()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.prepareBooleanQuery).\n",
    "\n",
    "Let’s check if there were any co-regencies in the time period\n",
    "described by our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareBooleanQuery(query=\"\"\"\n",
    "\n",
    "    ASK { ?ruler1 :reigned_from ?r1from ;\n",
    "                  :reigned_to ?r1to .\n",
    "          ?ruler2 :reigned_from ?r2from ;\n",
    "                  :reigned_to ?r2to .\n",
    "          FILTER (?ruler1 != ?ruler2 &&\n",
    "                  ?r1from >= ?r2from &&\n",
    "                  ?r1from < ?r2to)\n",
    "    }\"\"\")\n",
    "\n",
    "print(query.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was one (William and Mary):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONSTRUCT\n",
    "\n",
    "The CONSTRUCT query creates triples by substantiating provided\n",
    "templates with values resulting from matching a pattern. Queries of\n",
    "this kind are created using [prepareGraphQuery()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.prepareGraphQuery) and return a\n",
    "[RepositoryResult](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.repositoryresult.RepositoryResult) - which is an iterator over the constructed\n",
    "triples.\n",
    "\n",
    "Executing a CONSTRUCT query will *not* add any triples to the\n",
    "store. To insert the data we have to iterate over the result and\n",
    "add each triple using [addStatement()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.addStatement) (or use an INSERT\n",
    "query).\n",
    "\n",
    "Let us consider a query that calculates a :sibling_of\n",
    "relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size before: 19\n",
      "<ex://mary_ii> <-> <ex://anne>\n",
      "<ex://anne> <-> <ex://mary_ii>\n",
      "<ex://charles_ii> <-> <ex://james_ii>\n",
      "<ex://james_ii> <-> <ex://charles_ii>\n",
      "Size after: 19\n"
     ]
    }
   ],
   "source": [
    "print('Size before: {0}'.format(conn.size()))\n",
    "query = conn.prepareGraphQuery(query=\"\"\"\n",
    "   CONSTRUCT {\n",
    "       ?person1 :sibling_of ?person2 .\n",
    "   } WHERE {\n",
    "       ?person1 :child_of ?parent .\n",
    "       ?person2 :child_of ?parent .\n",
    "       filter (?person1 != ?person2) .\n",
    "   }\"\"\")\n",
    "for stmt in query.evaluate():\n",
    "    print('{0} <-> {1}'.format(stmt.getSubject(),\n",
    "                               stmt.getObject()))\n",
    "print('Size after: {0}'.format(conn.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned object is an iterator over [Statement](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.model.html#franz.openrdf.model.Statement) objects. We can\n",
    "also see that no data has been added to the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also serialize the result using any of the supported\n",
    "[RDFFormats](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.rio.html#franz.openrdf.rio.rdfformat.RDFFormat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://mary_ii> <ex://sibling_of> <ex://anne> .\n",
      "<ex://anne> <ex://sibling_of> <ex://mary_ii> .\n",
      "<ex://charles_ii> <ex://sibling_of> <ex://james_ii> .\n",
      "<ex://james_ii> <ex://sibling_of> <ex://charles_ii> .\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.rio.rdfformat import RDFFormat\n",
    "\n",
    "query.evaluate(output=True,\n",
    "               output_format=RDFFormat.NTRIPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the [N-Triples](https://www.w3.org/TR/n-triples/) format. This happens to be the default,\n",
    "so we could have omitted the output_format argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCRIBE\n",
    "\n",
    "The DESCRIBE query returns triples that ‘describe’ a given set of\n",
    "resources. Such queries are created using [prepareGraphQuery()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.prepareGraphQuery)\n",
    "and return [RepositoryResult](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.repositoryresult.RepositoryResult) objects.\n",
    "\n",
    "The set of resources to be processed is specified by a query\n",
    "pattern. The SPARQL standard does not say what triples constitute a\n",
    "‘description’ of a particular resource. AllegroGraph will return the\n",
    "[Concise Bounded Description](https://www.w3.org/Submission/CBD/) of the queried resources.\n",
    "\n",
    "Let’s use a DESCRIBE query to see what data do we have regarding\n",
    "the children of Charles I:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<ex://james_ii>, <ex://child_of>, <ex://charles_i>)\n",
      "(<ex://james_ii>, <ex://reigned_to>, \"1688-12-11\"^^<http://www.w3.org/2001/XMLSchema#date>)\n",
      "(<ex://james_ii>, <ex://reigned_from>, \"1685-02-06\"^^<http://www.w3.org/2001/XMLSchema#date>)\n",
      "(<ex://charles_ii>, <ex://child_of>, <ex://charles_i>)\n",
      "(<ex://charles_ii>, <ex://reigned_to>, \"1685-02-06\"^^<http://www.w3.org/2001/XMLSchema#date>)\n",
      "(<ex://charles_ii>, <ex://reigned_from>, \"1649-01-30\"^^<http://www.w3.org/2001/XMLSchema#date>)\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareGraphQuery(query=\"\"\"\n",
    "    DESCRIBE ?child WHERE {\n",
    "        ?child :child_of :charles_i\n",
    "    }\"\"\")\n",
    "for stmt in query.evaluate():\n",
    "    print(stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case AllegroGraph will simply return all triples with subject\n",
    "in the specified set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIBE queries can be useful for exploring a dataset and learning\n",
    "what properties a certain object might have. The results of such\n",
    "queries can be serialized to any supported [RDFFormat](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.rio.html#franz.openrdf.rio.rdfformat.RDFFormat):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://james_ii> <ex://child_of> <ex://charles_i> .\n",
      "<ex://james_ii> <ex://reigned_to> \"1688-12-11\"^^<http://www.w3.org/2001/XMLSchema#date> .\n",
      "<ex://james_ii> <ex://reigned_from> \"1685-02-06\"^^<http://www.w3.org/2001/XMLSchema#date> .\n",
      "<ex://charles_ii> <ex://child_of> <ex://charles_i> .\n",
      "<ex://charles_ii> <ex://reigned_to> \"1685-02-06\"^^<http://www.w3.org/2001/XMLSchema#date> .\n",
      "<ex://charles_ii> <ex://reigned_from> \"1649-01-30\"^^<http://www.w3.org/2001/XMLSchema#date> .\n"
     ]
    }
   ],
   "source": [
    "query.evaluate(output=True,\n",
    "               output_format=RDFFormat.NTRIPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example14'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 14: Parametric queries\n",
    "\n",
    "In previous examples our SPARQL queries were always fixed strings. In\n",
    "practice it is often necessary to include some variable elements\n",
    "(e.g. user input, results from another query, …) in the query\n",
    "strings.\n",
    "\n",
    "To illustrate, let us create a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and populate the repository with sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(r\"\"\"\n",
    "  @prefix : <ex://> .\n",
    "\n",
    "  :cipher42 :label \"RSA\" ; :code 1 .\n",
    "  :hedge1 :label \"\\\\/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\\" ; :code 2 .\n",
    "  :hedge2 :label \"/\\\\/\\\\/\\\\/\\\\/\\\\/\\\\//\" .  # No code\n",
    "  :has_no_label :secret \"squeamish ossifrage\" .\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we need a function that will take a search text and find\n",
    "all subjects that have a label containing a given search pattern. To\n",
    "make the query a little more interesting we’ll also print the value of\n",
    "the :code predicate for all subjects found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.setNamespace('', 'ex://')\n",
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    SELECT ?s ?code WHERE {\n",
    "       ?s :label ?o .\n",
    "       FILTER contains(?o, ?search)\n",
    "       OPTIONAL { ?s <ex://code> ?code } .\n",
    "    }\"\"\")\n",
    "\n",
    "def print_labelled_subjects(search_text):\n",
    "   query.setBinding('search', search_text)\n",
    "   query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a query object with a variable (?search) in place of the search pattern. To use it we have to provide a value for the variable. We do that using the [setBinding()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.query.html#franz.openrdf.query.query.Query.setBinding) method.\n",
    "\n",
    "Let’s check if our function works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "| s       | code |\n",
      "==================\n",
      "| :hedge1 | 2    |\n",
      "| :hedge2 | ---  |\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "print_labelled_subjects(r'\\/\\/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will return the ‘hedge’ subjects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String formatting\n",
    "\n",
    "Another way to achieve our goal would be to use formatting or string\n",
    "concatenation, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "| s         | code |\n",
      "====================\n",
      "| :cipher42 | 1    |\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "conn.setNamespace('', 'ex://')\n",
    "def print_labelled_subjects(search_text):\n",
    "    query = conn.prepareTupleQuery(query=\"\"\"\n",
    "        SELECT ?s ?code WHERE {\n",
    "            ?s :label ?o .\n",
    "            FILTER contains(?o, \"%s\")\n",
    "            OPTIONAL { ?s <ex://code> ?code } .\n",
    "        }\"\"\" % search_text)\n",
    "    query.evaluate(output=True)\n",
    "\n",
    "print_labelled_subjects('RS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But attempting to use a trickier input reveals a problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 MALFORMED QUERY: Line 4, Invalid literal \"\\\"\\\\/\\\\/\\\"\". Note that single backslashes in literals must be escaped. I.e., use '\\\\x', not '\\x'\n"
     ]
    },
    {
     "ename": "RequestError",
     "evalue": "Server returned 400: Line 4, Invalid literal \"\\\"\\\\/\\\\/\\\"\". Note that single backslashes in literals must be escaped. I.e., use '\\\\x', not '\\x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRequestError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-9faeebbeca88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint_labelled_subjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\/\\/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-130-434de6b045a5>\u001b[0m in \u001b[0;36mprint_labelled_subjects\u001b[1;34m(search_text)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mOPTIONAL\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m?\u001b[0m\u001b[0mcode\u001b[0m \u001b[1;33m}\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         }\"\"\" % search_text)\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint_labelled_subjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\franz-env\\lib\\site-packages\\franz\\openrdf\\query\\query.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, count, output, output_format)\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0maccept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mTupleFormat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmime_type_for_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m             response = self.evaluate_generic_query(\n\u001b[1;32m--> 325\u001b[1;33m                 count=count, accept=accept, callback=callback)\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\franz-env\\lib\\site-packages\\franz\\openrdf\\query\\query.py\u001b[0m in \u001b[0;36mevaluate_generic_query\u001b[1;34m(self, count, accept, callback, analyze, analysisTechnique, analysisTimeout, update)\u001b[0m\n\u001b[0;32m    262\u001b[0m                                             \u001b[0maccept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                                             \u001b[0manalyze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalysisTechnique\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0manalysisTechnique\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m                                             analysisTimeout=analysisTimeout, update=update)\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueryLanguage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mQueryLanguage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPROLOG\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnamedContexts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\franz-env\\lib\\site-packages\\franz\\miniclient\\repository.py\u001b[0m in \u001b[0;36mevalSparqlQuery\u001b[1;34m(self, query, infer, context, namedContext, callback, bindings, planner, checkVariables, count, accept, analyze, analysisTechnique, analysisTimeout, update)\u001b[0m\n\u001b[0;32m    291\u001b[0m                        queryAnalysisTimeout=analysisTimeout) + (bindings or \"\"),\n\u001b[0;32m    292\u001b[0m                        \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                        accept=accept)\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevalPrologQuery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\franz-env\\lib\\site-packages\\franz\\miniclient\\request.py\u001b[0m in \u001b[0;36mjsonRequest\u001b[1;34m(obj, method, url, body, content_type, callback, accept, headers)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mraiseErr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mRequestError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mmakeRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrCallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraiseErr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\franz-env\\lib\\site-packages\\franz\\miniclient\\backends\\requests.py\u001b[0m in \u001b[0;36mmakeRequest\u001b[1;34m(obj, method, url, body, accept, contentType, callback, errCallback, headers)\u001b[0m\n\u001b[0;32m    235\u001b[0m                     errCallback(response.status_code, \n\u001b[0;32m    236\u001b[0m                                 to_native_string(response.raw.read(\n\u001b[1;32m--> 237\u001b[1;33m                                     decode_content=True)))\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;31m# Note: no error callback in this case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\franz-env\\lib\\site-packages\\franz\\miniclient\\request.py\u001b[0m in \u001b[0;36mraiseErr\u001b[1;34m(status, message)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mRequestError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mdef\u001b[0m \u001b[0mraiseErr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mRequestError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[0mmakeRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrCallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraiseErr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRequestError\u001b[0m: Server returned 400: Line 4, Invalid literal \"\\\"\\\\/\\\\/\\\"\". Note that single backslashes in literals must be escaped. I.e., use '\\\\x', not '\\x'"
     ]
    }
   ],
   "source": [
    "print_labelled_subjects(r'\\/\\/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query is now invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A [devious user](https://xkcd.com/327/) could take advantage of this\n",
    "bug to access data that is not supposed to be available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| s         | code                |\n",
      "===================================\n",
      "| :cipher42 | squeamish ossifrage |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_labelled_subjects(\n",
    "    r'S\") optional { ?x <ex://secret> ?code } # ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should not be possible to reveal this literal by searching labels,\n",
    "and yet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work around this by ensuring proper escaping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "| s       | code |\n",
      "==================\n",
      "| :hedge1 | 2    |\n",
      "| :hedge2 | ---  |\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "def print_labelled_subjects(search_text):\n",
    "    search_lit = conn.createLiteral(search_text)\n",
    "    query = conn.prepareTupleQuery(query=\"\"\"\n",
    "        SELECT ?s ?code WHERE {\n",
    "            ?s :label ?o .\n",
    "            FILTER contains(?o, %s)\n",
    "            OPTIONAL { ?s <ex://code> ?code } .\n",
    "        }\"\"\" % search_lit.toNTriples())\n",
    "    query.evaluate(output=True)\n",
    "\n",
    "print_labelled_subjects(r'\\/\\/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function now works as expected:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example15'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 15: Range queries\n",
    "\n",
    "In many of the previous examples we have used the\n",
    "[getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) method to find all triples conforming to a given\n",
    "pattern. The patterns we have used so far matched each triple\n",
    "component against a single value. It is possible to use more complex\n",
    "patterns that can match a range of values for each component. To\n",
    "illustrate this let us first create a connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and construct some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "    @prefix : <ex://> .\n",
    "\n",
    "    :mercury a :planet ; :moons 0 .\n",
    "    :venus a :planet ; :moons 0 .\n",
    "    :earth a :planet ; :moons 1 .\n",
    "    :mars a :planet ; :moons 2 .\n",
    "    :jupiter a :planet ; :moons 67 .\n",
    "    :saturn a :planet ; :moons 62 .\n",
    "    :uranus a :planet ; :moons 27 .\n",
    "    :neptune a :planet ; :moons 14 .\n",
    "    :pluto a :dwarf_planet ; :moons 5 .\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we want to locate all planets that have at least one, but\n",
    "no more than five moons. To issue such a query we need to create a\n",
    "Range object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_to_five = conn.createRange(1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass the range object to [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://pluto>\n",
      "<ex://mars>\n",
      "<ex://earth>\n"
     ]
    }
   ],
   "source": [
    "moons = conn.createURI('ex://moons')\n",
    "with conn.getStatements(\n",
    "        None, moons, one_to_five) as result:\n",
    "    for statement in result:\n",
    "        print(statement.getSubject())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will find two planets and one dwarf planet, as expected:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments to [createRange()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.createRange) can be either RDF terms or\n",
    "regular Python values that will be converted to typed literals. In our example we used have used values of type int,\n",
    "which will be mapped to literals of type\n",
    "<http://www.w3.org/2001/XMLSchema#integer>. Range queries will\n",
    "only match values of exactly the same type. For instance if we add\n",
    "another triple to our store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "    @prefix : <ex://> .\n",
    "    @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "\n",
    "    :coruscant a :planet ; :moons \"4\"^^xsd:long .\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then reissue our query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://pluto>\n",
      "<ex://mars>\n",
      "<ex://earth>\n"
     ]
    }
   ],
   "source": [
    "with conn.getStatements(\n",
    "        None, moons, one_to_five) as result:\n",
    "    for statement in result:\n",
    "        print(statement.getSubject())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will find that the result has not changed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Range queries can also be performed with SPARQL, using FILTER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "| planet         |\n",
      "==================\n",
      "| ex://coruscant |\n",
      "| ex://pluto     |\n",
      "| ex://mars      |\n",
      "| ex://earth     |\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "conn.executeTupleQuery('''\n",
    "    SELECT ?planet {\n",
    "        ?planet <ex://moons> ?moons .\n",
    "        filter (?moons <= 5 && ?moons >= 1)\n",
    "    }''', output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the same as in the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the filter expression is a simple set of inequalities, as it is\n",
    "in this case, the query engine will use indices to optimize the query\n",
    "execution, similaraly to the way [getStatements()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection.getStatements) does for range\n",
    "queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='example16'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 16: Federated repositories\n",
    "\n",
    "AllegroGraph lets you split up your triples among repositories on\n",
    "multiple servers and then search them all in parallel. To do this we\n",
    "query a single “federated” repository that automatically distributes\n",
    "the queries to the secondary repositories and combines the\n",
    "results. From the point of view of your Python code, it looks like you\n",
    "are working with a single repository.\n",
    "\n",
    "To illustrate this, let us first create two repositories and import\n",
    "some data. The data will represent positive numbers below 15. The\n",
    "first repository will contain all Fibonacci numbers in that range,\n",
    "while the second one will contain all other numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "with ag_connect('python_fib', create=True, clear=True) as conn:\n",
    "    conn.addData(\"\"\"\n",
    "        @prefix : <ex://> .\n",
    "\n",
    "        :one :value 1 .\n",
    "        :two :value 2 .\n",
    "        :three :value 3 .\n",
    "        :five :value 5 .\n",
    "        :eight :value 8 .\n",
    "        :thirteen :value 13 .\n",
    "    \"\"\")\n",
    "\n",
    "with ag_connect('python_boring', create=True, clear=True) as conn:\n",
    "    conn.addData(\"\"\"\n",
    "        @prefix : <ex://> .\n",
    "\n",
    "        :four :value 4 .\n",
    "        :six :value 6 .\n",
    "        :seven :value 7 .\n",
    "        :nine :value 9 .\n",
    "        :ten :value 10 .\n",
    "        :eleven :value 11 .\n",
    "        :twelve :value 12 .\n",
    "        :fourteen :value 14 .\n",
    "        :fifteen :value 15 .\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a federated repository, we first have to connect to the\n",
    "server that will be used to aggregate results. We do this by creating\n",
    "an [AllegroGraphServer](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.sail.html#franz.openrdf.sail.allegrographserver.AllegroGraphServer) instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.sail.allegrographserver import AllegroGraphServer\n",
    "\n",
    "server = AllegroGraphServer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using default server address and credentials, as described in\n",
    "the [Setting the environment for the tutorial](setup.ipynb#setup) section of the tutorial.\n",
    "\n",
    "The next step is to use the [openFederated()](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.sail.html#franz.openrdf.sail.allegrographserver.AllegroGraphServer.openFederated)\n",
    "method to create a federated session. We will pass the list of\n",
    "repositories to federate as an argument. Elements of this list could\n",
    "be\n",
    "\n",
    "- [Repository](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repository.Repository) objects  \n",
    "- [RepositoryConnection](https://franz.com/agraph/support/documentation/6.4.0/python/_gen/franz.openrdf.repository.html#franz.openrdf.repository.repositoryconnection.RepositoryConnection) objects  \n",
    "- strings (naming a store in the root catalog, or the URL of a\n",
    "  store)  \n",
    "- (storename, catalogname) tuples.  \n",
    "  \n",
    "\n",
    "We’ll use the third option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = server.openFederated(['python_fib', 'python_boring'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query the combined repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "| avg | min | max |\n",
      "===================\n",
      "| 8.0 | 1   | 15  |\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "query = conn.prepareTupleQuery(query=\"\"\"\n",
    "    select (avg(?v) as ?avg)\n",
    "           (min(?v) as ?min)\n",
    "           (max(?v) as ?max) where {\n",
    "       ?number <ex://value> ?v .\n",
    "    }\"\"\")\n",
    "query.evaluate(output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, data from both repositories has been returned and\n",
    "aggregates have been correctly computed over the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of using federated repositories, this time with\n",
    "multiple server machines, can be found in [Running AG on AWS EC2](fedex.ipynb#fedex).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 17: Triple Attributes\n",
    "\n",
    "Triples offer a way of describing model elements and relationships between them. In come cases, however, it is also convenient to be able to store data that is associated with a triple as a whole rather than with a particular element. For instance one might wish to record the source from which a triple has been imported or access level necessary to include it in query results. Traditional solutions of this problem include using graphs, RDF reification or triple IDs. All of these approaches suffer from various flexibility and performance issues. For this reason AllegroGraph offers an alternative: triple attributes.\n",
    "\n",
    "Attributes are key-value pairs associated with a triple. Keys refer to attribute definitions that must be added to the store before they are used. Values are strings. The set of legal values of an attribute can be constrained by the definition of that attribute. It is possible to associate multiple values of a given attribute with a single triple.\n",
    "\n",
    "Possible uses for triple attributes include:\n",
    "\n",
    "* Access control: It is possible to instruct AllegroGraph to prevent an user from accessing triples with certain attributes.\n",
    "* Sharding: Attributes can be used to ensure that related triples are always placed in the same shard when AllegroGraph acts as a distributed triple store.\n",
    "\n",
    "Like all other triple components, attribute values are immutable. They must be provided when the triple is added to the store and cannot be changed or removed later.\n",
    "\n",
    "To illustrate the use of triple attributes we will construct an artificial data set containing a log of information about contacts detected by a submarine at a single moment in time.\n",
    "\n",
    "## Managing attribute definitions\n",
    "\n",
    "Before we can add triples with attributes to the store we must create appropriate attribute definitions.\n",
    "\n",
    "First let’s open a connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute definitions are represented by **AttributeDefinition** objects. Each definition has a name, which must be unique, and a few optional properties (that can also be passed as constructor arguments):\n",
    "\n",
    "* `allowed_values`: a list of strings. If this property is set then only the values from this list can be used for the defined attribute.\n",
    "* `ordered`: a boolean. If true then attribute value comparisons will use the ordering defined by `allowed_values`. The default is false.\n",
    "* `minimum_number`, `maximum_number`: integers that can be used to constrain the cardinality of an attribute. By default there are no limits.\n",
    "\n",
    "Let’s define a few attributes that we will later use to demonstrate various attribute-related capabilities of AllegroGraph. To do this, we will use the **setAttributeDefinition()** method of the connection object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.repository.attributes import AttributeDefinition\n",
    "\n",
    "# A simple attribute with no constraints governing the set\n",
    "# of legal values or the number of values that can be\n",
    "# associated with a triple.\n",
    "tag = AttributeDefinition(name='tag')\n",
    "\n",
    "# An attribute with a limited set of legal values.\n",
    "# Every bit of data can come from multiple sources.\n",
    "# We encode this information in triple attributes,\n",
    "# since it refers to the tripe as a whole. Another\n",
    "# way of achieving this would be to use triple ids\n",
    "# or RDF reification.\n",
    "source = AttributeDefinition(\n",
    "    name='source',\n",
    "    allowed_values=['sonar', 'radar', 'esm', 'visual'])\n",
    "\n",
    "# Security level - notice that the values are ordered\n",
    "# and each triple *must* have exactly one value for\n",
    "# this attribute. We will use this to prevent some\n",
    "# users from accessing classified data.\n",
    "level = AttributeDefinition(\n",
    "    name='level',\n",
    "    allowed_values=['low', 'medium', 'high'],\n",
    "    ordered=True,\n",
    "    minimum_number=1,\n",
    "    maximum_number=1)\n",
    "\n",
    "# An attribute like this could be used for sharding.\n",
    "# That would ensure that data related to a particular\n",
    "# contact is never partitioned across multiple shards.\n",
    "# Note that this attribute is required, since without\n",
    "# it an attribute-sharded triple store would not know\n",
    "# what to do with a triple.\n",
    "contact = AttributeDefinition(\n",
    "    name='contact',\n",
    "    minimum_number=1,\n",
    "    maximum_number=1)\n",
    "\n",
    "# So far we have created definition objects, but we\n",
    "# have not yet sent those definitions to the server.\n",
    "# Let's do this now.\n",
    "conn.setAttributeDefinition(tag)\n",
    "conn.setAttributeDefinition(source)\n",
    "conn.setAttributeDefinition(level)\n",
    "conn.setAttributeDefinition(contact)\n",
    "\n",
    "# This line is not strictly necessary, because our\n",
    "# connection operates in autocommit mode.\n",
    "# However, it is important to note that attribute\n",
    "# definitions have to be committed before they can\n",
    "# be used by other sessions.\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to retrieve the list of attribute definitions from a repository by using the **getAttributeDefinitions()** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tag\n",
      "Min count: 0\n",
      "Max count: 1152921504606846975\n",
      "\n",
      "Name: source\n",
      "Allowed values: sonar, radar, esm, visual\n",
      "Ordered: N\n",
      "Min count: 0\n",
      "Max count: 1152921504606846975\n",
      "\n",
      "Name: level\n",
      "Allowed values: low, medium, high\n",
      "Ordered: Y\n",
      "Min count: 1\n",
      "Max count: 1\n",
      "\n",
      "Name: contact\n",
      "Min count: 1\n",
      "Max count: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we want to ignore system attributes and only\n",
    "# look for attributes we've added\n",
    "expected = [\"tag\", \"source\", \"level\", \"contact\"]\n",
    "for attr in conn.getAttributeDefinitions():\n",
    "    if attr.name not in expected: continue\n",
    "    print('Name: {0}'.format(attr.name))\n",
    "    if attr.allowed_values:\n",
    "        print('Allowed values: {0}'.format(\n",
    "            ', '.join(attr.allowed_values)))\n",
    "        print('Ordered: {0}'.format(\n",
    "            'Y' if attr.ordered else 'N'))\n",
    "    print('Min count: {0}'.format(attr.minimum_number))\n",
    "    print('Max count: {0}'.format(attr.maximum_number))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in cases where the maximum cardinality has not been explicitly defined, the server replaced it with a default value. In practice this value is high enough to be interpreted as ‘no limit’.\n",
    "\n",
    "Attribute definitions can be removed (provided that the attribute is not used by the static attribute filter, which will be discussed later) by calling **deleteAttributeDefinition()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contact, level, source\n"
     ]
    }
   ],
   "source": [
    "conn.deleteAttributeDefinition('tag')\n",
    "possible = [\"tag\", \"source\", \"level\", \"contact\"]\n",
    "defs = conn.getAttributeDefinitions()\n",
    "# there may be system attributes and we want\n",
    "# to ignore them and only look at the ones\n",
    "# we've added\n",
    "filtered_defs = [attr for attr in defs if attr.name in possible]\n",
    "print(', '.join(sorted(a.name for a in filtered_defs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding triples with attributes\n",
    "\n",
    "Now that the attribute definitions have been established we can demonstrate the process of adding triples with attributes. This can be achieved using various methods. A common element of all these methods is the way in which triple attributes are represented. In all cases dictionaries with attribute names as keys and strings or lists of strings as values are used.\n",
    "\n",
    "When **addTriple()** is used it is possible to pass attributes in a keyword parameter, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = conn.namespace('ex://')\n",
    "conn.addTriple(ex.S1, ex.cls, ex.Udaloy, attributes={\n",
    "    'source': 'sonar',\n",
    "    'level': 'low',\n",
    "    'contact': 'S1'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **addStatement()** method works in similar way. Note that it is not possible to include attributes in the **Statement** object itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.model import Statement\n",
    "\n",
    "s = Statement(ex.M1, ex.cls, ex.Zumwalt)\n",
    "conn.addStatement(s, attributes={\n",
    "    'source': ['sonar', 'esm'],\n",
    "    'level': 'medium',\n",
    "    'contact': 'M1'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding multiple triples with **addTriples()** one can add a fifth element to each tuple to represent attributes. Let us illustrate this by adding an aircraft to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addTriples(\n",
    "    [(ex.R1, ex.cls, ex['Ka-27'], None,\n",
    "      {'source': 'radar',\n",
    "       'level': 'low',\n",
    "       'contact': 'R1'}),\n",
    "     (ex.R1, ex.altitude, 200, None,\n",
    "      {'source': 'radar',\n",
    "       'level': 'medium',\n",
    "       'contact': 'R1'})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all or most of the added triples share the same attribute set it might be convenient to use the attributes keyword parameter. This provides default values, but is completely ignored for all tuples that already contain attributes (the dictionaries are not merged). In the example below we add a triple representing an aircraft carrier and a few more triples that specify its position. Notice that the first triple has a lower security level and multiple sources. The common ‘contact’ attribute could be used to ensure that all this data will remain on a single shard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addTriples(\n",
    "    [(ex.M2, ex.cls, ex.Kuznetsov, None, {\n",
    "        'source': ['sonar', 'radar', 'visual'],\n",
    "        'contact': 'M2',\n",
    "        'level': 'low',\n",
    "     }),\n",
    "     (ex.M2, ex.position, ex.pos343),\n",
    "     (ex.pos343, ex.x, 430.0),\n",
    "     (ex.pos343, ex.y, 240.0)],\n",
    "    attributes={\n",
    "       'contact': 'M2',\n",
    "       'source': 'radar',\n",
    "       'level': 'medium'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method of adding triples with attributes is to use the NQX file format. This works both with **addFile()** and **addData()** (illustrated below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.rio.rdfformat import RDFFormat\n",
    "\n",
    "conn.addData('''\n",
    "    <ex://S2> <ex://cls> <ex://Alpha> \\\n",
    "    {\"source\": \"sonar\", \"level\": \"medium\", \"contact\": \"S2\"} .\n",
    "    <ex://S2> <ex://depth> \"300\" \\\n",
    "    {\"source\": \"sonar\", \"level\": \"medium\", \"contact\": \"S2\"} .\n",
    "    <ex://S2> <ex://speed_kn> \"15.0\" \\\n",
    "    {\"source\": \"sonar\", \"level\": \"medium\", \"contact\": \"S2\"} . ''', rdf_format=RDFFormat.NQX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When importing from a format that does not support attributes, it is possible to provide a common set of attribute values with a keyword parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.rio.rdfformat import RDFFormat\n",
    "\n",
    "conn.addData('''\n",
    "    <ex://V1> <ex://cls> <ex://Walrus> ;\n",
    "              <ex://altitude> 100 ;\n",
    "              <ex://speed_kn> 12.0e+8 .\n",
    "    <ex://V2> <ex://cls> <ex://Walrus> ;\n",
    "              <ex://altitude> 200 ;\n",
    "              <ex://speed_kn> 12.0e+8 .\n",
    "    <ex://V3> <ex://cls> <ex://Walrus> ;\n",
    "              <ex://altitude> 300;\n",
    "              <ex://speed_kn> 12.0e+8 .\n",
    "    <ex://V4> <ex://cls> <ex://Walrus> ;\n",
    "              <ex://altitude> 400 ;\n",
    "              <ex://speed_kn> 12.0e+8 .\n",
    "    <ex://V5> <ex://cls> <ex://Walrus> ;\n",
    "              <ex://altitude> 500 ;\n",
    "              <ex://speed_kn> 12.0e+8 .\n",
    "    <ex://V6> <ex://cls> <ex://Walrus> ;\n",
    "              <ex://altitude> 600 ;\n",
    "              <ex://speed_kn> 12.0e+8 .\n",
    "''', attributes={\n",
    "    'source': 'visual',\n",
    "    'level': 'high',\n",
    "    'contact': 'a therapist'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data above represents six visually observed Walrus-class submarines, flying at different altitudes and well above the speed of light. It has been highly classified to conceal the fact that someone has clearly been drinking while on duty - after all there are only four Walrus-class submarines currently in service, so the observation is obviously incorrect.\n",
    "\n",
    "## Retrieving attribute values¶\n",
    "\n",
    "We will now print all the data we have added to the store, including attributes, to verify that everything worked as expected. The only way to do that is through a SPARQL query using the appropriate [magic property](https://franz.com/ns/allegrograph/6.2.0/attributes) to access the attributes. The query below binds a literal containing a JSON representation of triple attributes to the _?a_ variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ex://M1> <ex://cls> <ex://Zumwalt>\n",
      "{\n",
      "    \"contact\": \"M1\",\n",
      "    \"level\": \"medium\",\n",
      "    \"source\": [\n",
      "        \"esm\",\n",
      "        \"sonar\"\n",
      "    ]\n",
      "}\n",
      "<ex://M2> <ex://cls> <ex://Kuznetsov>\n",
      "{\n",
      "    \"contact\": \"M2\",\n",
      "    \"level\": \"low\",\n",
      "    \"source\": [\n",
      "        \"visual\",\n",
      "        \"radar\",\n",
      "        \"sonar\"\n",
      "    ]\n",
      "}\n",
      "<ex://M2> <ex://position> <ex://pos343>\n",
      "{\n",
      "    \"contact\": \"M2\",\n",
      "    \"level\": \"medium\",\n",
      "    \"source\": \"radar\"\n",
      "}\n",
      "<ex://R1> <ex://altitude> \"200\"^^<http://www.w3.org/2001/XMLSchema#integer>\n",
      "{\n",
      "    \"contact\": \"R1\",\n",
      "    \"level\": \"medium\",\n",
      "    \"source\": \"radar\"\n",
      "}\n",
      "<ex://R1> <ex://cls> <ex://Ka-27>\n",
      "{\n",
      "    \"contact\": \"R1\",\n",
      "    \"level\": \"low\",\n",
      "    \"source\": \"radar\"\n",
      "}\n",
      "<ex://S1> <ex://cls> <ex://Udaloy>\n",
      "{\n",
      "    \"contact\": \"S1\",\n",
      "    \"level\": \"low\",\n",
      "    \"source\": \"sonar\"\n",
      "}\n",
      "<ex://S2> <ex://cls> <ex://Alpha>\n",
      "{\n",
      "    \"contact\": \"S2\",\n",
      "    \"level\": \"medium\",\n",
      "    \"source\": \"sonar\"\n",
      "}\n",
      "<ex://S2> <ex://depth> \"300\"\n",
      "{\n",
      "    \"contact\": \"S2\",\n",
      "    \"level\": \"medium\",\n",
      "    \"source\": \"sonar\"\n",
      "}\n",
      "<ex://S2> <ex://speed_kn> \"15.0\"\n",
      "{\n",
      "    \"contact\": \"S2\",\n",
      "    \"level\": \"medium\",\n",
      "    \"source\": \"sonar\"\n",
      "}\n",
      "<ex://V1> <ex://altitude> \"100\"^^<http://www.w3.org/2001/XMLSchema#integer>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V1> <ex://cls> <ex://Walrus>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V1> <ex://speed_kn> \"1.2E9\"^^<http://www.w3.org/2001/XMLSchema#double>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V2> <ex://altitude> \"200\"^^<http://www.w3.org/2001/XMLSchema#integer>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V2> <ex://cls> <ex://Walrus>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V2> <ex://speed_kn> \"1.2E9\"^^<http://www.w3.org/2001/XMLSchema#double>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V3> <ex://altitude> \"300\"^^<http://www.w3.org/2001/XMLSchema#integer>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V3> <ex://cls> <ex://Walrus>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V3> <ex://speed_kn> \"1.2E9\"^^<http://www.w3.org/2001/XMLSchema#double>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V4> <ex://altitude> \"400\"^^<http://www.w3.org/2001/XMLSchema#integer>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V4> <ex://cls> <ex://Walrus>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V4> <ex://speed_kn> \"1.2E9\"^^<http://www.w3.org/2001/XMLSchema#double>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V5> <ex://altitude> \"500\"^^<http://www.w3.org/2001/XMLSchema#integer>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V5> <ex://cls> <ex://Walrus>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V5> <ex://speed_kn> \"1.2E9\"^^<http://www.w3.org/2001/XMLSchema#double>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V6> <ex://altitude> \"600\"^^<http://www.w3.org/2001/XMLSchema#integer>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V6> <ex://cls> <ex://Walrus>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://V6> <ex://speed_kn> \"1.2E9\"^^<http://www.w3.org/2001/XMLSchema#double>\n",
      "{\n",
      "    \"contact\": \"a therapist\",\n",
      "    \"level\": \"high\",\n",
      "    \"source\": \"visual\"\n",
      "}\n",
      "<ex://pos343> <ex://x> \"4.3E2\"^^<http://www.w3.org/2001/XMLSchema#double>\n",
      "{\n",
      "    \"contact\": \"M2\",\n",
      "    \"level\": \"medium\",\n",
      "    \"source\": \"radar\"\n",
      "}\n",
      "<ex://pos343> <ex://y> \"2.4E2\"^^<http://www.w3.org/2001/XMLSchema#double>\n",
      "{\n",
      "    \"contact\": \"M2\",\n",
      "    \"level\": \"medium\",\n",
      "    \"source\": \"radar\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "r = conn.executeTupleQuery('''\n",
    "   PREFIX attr: <http://franz.com/ns/allegrograph/6.2.0/>\n",
    "   SELECT ?s ?p ?o ?a {\n",
    "       ?s ?p ?o .\n",
    "       ?a attr:attributes (?s ?p ?o) .\n",
    "   } ORDER BY ?s ?p ?o''')\n",
    "with r:\n",
    "    for row in r:\n",
    "        print(row['s'], row['p'], row['o'])\n",
    "        print(json.dumps(json.loads(row['a'].label),\n",
    "                         sort_keys=True,\n",
    "                         indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result contains all the expected triples with pretty-printed attributes.\n",
    "\n",
    "## Attribute filters\n",
    "\n",
    "Triple attributes can be used to provide fine-grained access control. This can be achieved by using static attribute filters.\n",
    "\n",
    "Static attribute filters are simple expressions that control which triples are visible to a query based on triple attributes. Each repository has a single, global attribute filter that can be modified using **setAttributeFilter()**. The values passed to this method must be either strings (the syntax is described in the documentation of static attribute filters) or filter objects.\n",
    "\n",
    "Filter objects are created by applying set operators to ‘attribute sets’. These can then be combined using filter operators.\n",
    "\n",
    "An attribute set can be one of the following:\n",
    "\n",
    "* a string or a list of strings: represents a constant set of values.\n",
    "* _TripleAttribute.name_: represents the value of the name attribute associated with the currently inspected triple.\n",
    "* _UserAttribute.name_: represents the value of the name attribute associated with current query. User attributes will be discussed in more detail later.\n",
    "\n",
    "Available set operators are shown in the table below. All classes and functions mentioned here can be imported from the `franz.openrdf.repository.attributes` package:\n",
    "\n",
    "| **Syntax** | **Meaning** |\n",
    "|:------------|:-------------|\n",
    "|      `Empty(x)`      |       True if the specified attribute set is empty.      |\n",
    "|     `Overlap(x, y)`       |       True if there is at least one matching value between the two attribute sets.      |\n",
    "|       `Subset(x, y)`, `x << y`     |        True if every element of _x_ can be found in _y_     |\n",
    "|       `Superset(x, y)`, `x >> y`     |        True if every element of _y_ can be found in _x_     |\n",
    "|      `Equal(x, y)`, `x == y`      |       True if _x_ and _y_ have exactly the same contents.      |\n",
    "|     `Lt(x, y)`, `x < y`       |       True if both sets are singletons, at least one of the sets refers to a triple or user attribute, the attribute is ordered and the value of the single element of _x_ occurs before the single value of _y_ in the `lowed_values` list of the attribute.      |\n",
    "|      `Le(x, y)`, `x <= y`      |       True if _y_ < _x_ is false.      |\n",
    "|      `Eq(x, y)`      |      True if both _x_ < _y_ and _y_ < _x_ are false. Note that using the == Python operator translates to `Equals`, not `Eq`.       |\n",
    "|      `Ge(x, y)`, `x >= y`      |      True if _x_ < _y_ is false.       |\n",
    "|     `Gt(x, y), x > y`       |       True if _y_ < _x_.      |\n",
    "\n",
    "\n",
    "Note that the overloaded operators only work if at least one of the attribute sets is a `UserAttribute` or `TripleAttribute` reference - if both arguments are strings or lists of strings the default Python semantics for each operator are used. The prefix syntax always produces filters.\n",
    "\n",
    "Filters can be combined using the following operators:\n",
    "\n",
    "| **Syntax** | **Meaning** |\n",
    "|:------------|:-------------|\n",
    "|       `Not(x)`, `~x`     |        Negates the meaning of the filter.     |\n",
    "|      `And(x, y, ...)`, `x & y`      |       True if all subfilters are true.      |\n",
    "|     `Or(x, y, ...)`, `x \\| y`       |       True if at least one subfilter is true.      |\n",
    "\n",
    "Filter operators also work with raw strings, but overloaded operators will only be recognized if at least one argument is a filter object.\n",
    "\n",
    "## Using filters and user attributes\n",
    "\n",
    "The example below displays all classes of vessels from the dataset after establishing a static attribute filter which ensures that only sonar contacts are visible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "| class          |\n",
      "==================\n",
      "| ex://Alpha     |\n",
      "| ex://Kuznetsov |\n",
      "| ex://Udaloy    |\n",
      "| ex://Zumwalt   |\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "from franz.openrdf.repository.attributes import *\n",
    "\n",
    "conn.setAttributeFilter(TripleAttribute.source >> 'sonar')\n",
    "conn.executeTupleQuery(\n",
    "    'select ?class { ?s <ex://cls> ?class } order by ?class',\n",
    "    output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output contains neither the visually observed Walruses nor the radar detected ASW helicopter.\n",
    "\n",
    "To avoid having to set a static filter before each query (which would be inefficient and cause concurrency issues) we can employ user attributes. User attributes are specific to a particular connection and are sent to the server with each query. The static attribute filter can refer to these and compare them with triple attributes. Thus we can use code presented below to create a filter which ensures that a connection only accesses data at or below the chosen clearance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "| class          |\n",
      "==================\n",
      "| ex://Ka-27     |\n",
      "| ex://Kuznetsov |\n",
      "| ex://Udaloy    |\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "conn.setUserAttributes({'level': 'low'})\n",
    "conn.setAttributeFilter(\n",
    "    TripleAttribute.level <= UserAttribute.level)\n",
    "conn.executeTupleQuery(\n",
    "    'select ?class { ?s <ex://cls> ?class } order by ?class',\n",
    "    output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the output here contains only contacts with the access level of low. It omits the destroyer and Alpha submarine (these require medium level) as well as the top-secret Walruses.\n",
    "\n",
    "```\n",
    "------------------\n",
    "| class          |\n",
    "==================\n",
    "| ex://Ka-27     |\n",
    "| ex://Kuznetsov |\n",
    "| ex://Udaloy    |\n",
    "------------------\n",
    "```\n",
    "\n",
    "The main advantage of the code presented above is that the filter can be set globally during the application setup and access control can then be achieved by varying user attributes on connection objects.\n",
    "\n",
    "Let us now remove the attribute filter to prevent it from interfering with other examples. We will use the **clearAttributeFilter()** method.\n",
    "\n",
    "```\n",
    "conn.clearAttributeFilter()\n",
    "```\n",
    "\n",
    "It might be useful to change connection’s attributes temporarily for the duration of a single code block and restore prior attributes after that. This can be achieved using the **temporaryUserAttributes()** method, which returns a context manager. The example below illustrates its use. It also shows how to use **getUserAttributes()** to inspect user attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User attributes inside the block:\n",
      "level: high\n",
      "\n",
      "User attributes outside the block:\n",
      "level: low\n"
     ]
    }
   ],
   "source": [
    "with conn.temporaryUserAttributes({'level': 'high'}):\n",
    "    print('User attributes inside the block:')\n",
    "    for k, v in conn.getUserAttributes().items():\n",
    "        print('{0}: {1}'.format(k, v))\n",
    "    print()\n",
    "print('User attributes outside the block:')\n",
    "for k, v in conn.getUserAttributes().items():\n",
    "    print('{0}: {1}'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "User attributes inside the block:\n",
    "level: high\n",
    "\n",
    "User attributes outside the block:\n",
    "level: low\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 18: Pandas support\n",
    "\n",
    "The SPARQL query language has somewhat limited capabilities when it comes to advanced numerical data analysis, data mining and other similar tasks. In these cases it is best to only use SPARQL to extract, filter and normalize data (perhaps coming from diverse sources - the ability to work with such data is one of the key advantages of the RDF data model) and rely on other tools to perform further analysis. One of the more popular tools that can be used in this context is the [Pandas framework](https://pandas.pydata.org/). The AllegroGraph Python client contains basic support for processing query results with this library. Let us see how this support can be leveraged in a simplified scenario.\n",
    "\n",
    "As usual, we will start by opening a connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "\n",
    "conn = ag_connect('python-tutorial', create=True, clear=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add some data. The first data set describes per capita cheese consumption in the United States in years 2000-2009 according to USDA. The values are expressed in pounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData('''\n",
    "    prefix ex: <ex://>\n",
    "    ex:c2000 ex:year 2000; ex:cheese 29.8 .\n",
    "    ex:c2001 ex:year 2001; ex:cheese 30.1 .\n",
    "    ex:c2002 ex:year 2002; ex:cheese 30.5 .\n",
    "    ex:c2003 ex:year 2003; ex:cheese 30.6 .\n",
    "    ex:c2004 ex:year 2004; ex:cheese 31.3 .\n",
    "    ex:c2005 ex:year 2005; ex:cheese 31.7 .\n",
    "    ex:c2006 ex:year 2006; ex:cheese 32.6 .\n",
    "    ex:c2007 ex:year 2007; ex:cheese 33.1 .\n",
    "    ex:c2008 ex:year 2008; ex:cheese 32.7 .\n",
    "    ex:c2009 ex:year 2009; ex:cheese 32.8 .\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second set of samples is derived from NSF data and describes the number of civil engineering doctorates awarded each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData('''\n",
    "    prefix ex: <ex://>\n",
    "    ex:d2000 ex:year 2000; ex:doctorates 480 .\n",
    "    ex:d2001 ex:year 2001; ex:doctorates 501 .\n",
    "    ex:d2002 ex:year 2002; ex:doctorates 540 .\n",
    "    ex:d2003 ex:year 2003; ex:doctorates 552 .\n",
    "    ex:d2004 ex:year 2004; ex:doctorates 547 .\n",
    "    ex:d2005 ex:year 2005; ex:doctorates 622 .\n",
    "    ex:d2006 ex:year 2006; ex:doctorates 655 .\n",
    "    ex:d2007 ex:year 2007; ex:doctorates 701 .\n",
    "    ex:d2008 ex:year 2008; ex:doctorates 712 .\n",
    "    ex:d2009 ex:year 2009; ex:doctorates 708 .\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a SPARQL query to extract all this data and create a Pandas DataFrame from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year cheese  doctorates\n",
      "0  2000   29.8         480\n",
      "1  2001   30.1         501\n",
      "2  2002   30.5         540\n",
      "3  2003   30.6         552\n",
      "4  2004   31.3         547\n",
      "5  2005   31.7         622\n",
      "6  2006   32.6         655\n",
      "7  2007   33.1         701\n",
      "8  2008   32.7         712\n",
      "9  2009   32.8         708\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "prefix ex: <ex://>\n",
    "select ?year ?cheese ?doctorates {\n",
    "    _:b1 ex:year ?year ; ex:cheese ?cheese .\n",
    "    _:b2 ex:year ?year ; ex:doctorates ?doctorates .\n",
    "} order by ?year'''\n",
    "with conn.executeTupleQuery(query) as result:\n",
    "    df = result.toPandas()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the DataFrame can be used after the result has been discarded, since all required data has been copied.\n",
    "\n",
    "At this point the **TupleQueryResult.toPandas()** method does not allow fine-grained control over types of the returned columns. The `'cheese'` column contains decimal values, but floats would be more convenient for further computation. Thus we will modify the dataframe and convert the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cheese'] = df['cheese'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data in a form suitable for Pandas, we can perform some analysis. To keep this tutorial simple we will just measure the correlation between the number of civil engineering doctorates awarded and per capita cheese consumption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.97433\n"
     ]
    }
   ],
   "source": [
    "correlation = df.corr()['cheese']['doctorates']\n",
    "print(\"Correlation: %.5f\" % correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation of this result is left as an exercise to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 19: Using JSON-LD\n",
    "\n",
    "JSON-LD is described pretty well at [https://json-ld.org/](https://json-ld.org/) and the specification can be found at [https://json-ld.org/latest/json-ld/](https://json-ld.org/latest/json-ld/) .\n",
    "\n",
    "The website [https://json-ld.org/playground/](https://json-ld.org/playground/) is also useful.\n",
    "\n",
    "There are many reasons for working with JSON-LD. The major search engines such as Google require ecommerce companies to mark up their websites with a systematic description of their products and more and more companies use it as an easy serialization format to share data.\n",
    "\n",
    "The benefit for your organization is that you can now combine your documents with graphs, graph search and graph algorithms. Normally when you store documents in a document store you set up your documents in such a way that it is optimized for direct retrieval queries. Doing complex joins for multiple types of documents or even doing a shortest path through a mass of object (types) is however very complicated. Storing JSON-LD objects in AllegroGraph gives you all the benefits of a document store and you can semantically link objects together, do complex joins and even graph search.\n",
    "\n",
    "A second benefit is that, as an application developer, you do not have to learn the entire semantic technology stack, especially the part where developers have to create individual triples or edges. You can work with the JSON data serialization format that application developers usually prefer.\n",
    "\n",
    "In the following you will first learn about JSON-LD as a syntax for semantic graphs. After that we will talk more about using JSON-LD with AllegroGraph as a document-graph-store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "with ag_connect('repo') as conn:\n",
    "    print(conn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the script runs successfully a new repository named repo will be created.\n",
    "\n",
    "## JSON-LD setup\n",
    "\n",
    "We next define some utility functions which are somewhat different from what we have used before in order to work better with JSON-LD. **createdb()** creates and opens a new repository and **opendb()** opens an existing repo (modify the values of host, port, user, and password arguments in the definitions if necessary). Both return repository connections which can be used to perform repository operations. **showtriples()** displays triples in a repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json, requests, copy\n",
    "\n",
    "from franz.openrdf.sail.allegrographserver import AllegroGraphServer\n",
    "from franz.openrdf.connect import ag_connect\n",
    "from franz.openrdf.vocabulary.xmlschema import XMLSchema\n",
    "from franz.openrdf.rio.rdfformat import RDFFormat\n",
    "\n",
    "# Functions to create/open a repo and return a RepositoryConnection\n",
    "\n",
    "def createdb(name):\n",
    "    return ag_connect(name, create=True, clear=True)\n",
    "\n",
    "def opendb(name):\n",
    "    return ag_connect(name, create=False)\n",
    "\n",
    "def showtriples(limit=100):\n",
    "    statements = conn.getStatements(limit=limit)\n",
    "    with statements:\n",
    "        for statement in statements:\n",
    "             print(statement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we call our **createdb** function to create a repository and return a _RepositoryConnection_ to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn=createdb('jsonplay')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Examples of Using JSON-LD\n",
    "\n",
    "In the following we try things out with some JSON-LD objects that are defined in json-ld playground: jsonld\n",
    "\n",
    "The first object we will create is an event dict. Although it is a Python dict, it is also valid JSON notation. (But note that not all Python dictionaries are valid JSON. For example, JSON uses null where Python would use None and there is no magic to automatically handle that.) This object has one key called @context which specifies how to translate keys and values into predicates and objects. The following `@context` says that every time you see ical: it should be replaced by `http://www.w3.org/2002/12/cal/ical#`, `xsd:` by `http://www.w3.org/2001/XMLSchema#`, and that if you see `ical:dtstart` as a key than the value should be treated as an `xsd:dateTime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\n",
    "  \"@context\": {\n",
    "    \"ical\": \"http://www.w3.org/2002/12/cal/ical#\",\n",
    "    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "    \"ical:dtstart\": { \"@type\": \"xsd:dateTime\" }\n",
    "      },\n",
    "    \"ical:summary\": \"Lady Gaga Concert\",\n",
    "    \"ical:location\": \"New Orleans Arena, New Orleans, Louisiana, USA\",\n",
    "    \"ical:dtstart\": \"2011-04-09T20:00:00Z\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try it out (the subjects are blank nodes so you will see different values):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(_:bF080D75Fx1, <http://www.w3.org/2002/12/cal/ical#summary>, \"Lady Gaga Concert\")\n",
      "(_:bF080D75Fx1, <http://www.w3.org/2002/12/cal/ical#location>, \"New Orleans Arena, New Orleans, Louisiana, USA\")\n",
      "(_:bF080D75Fx1, <http://www.w3.org/2002/12/cal/ical#dtstart>, \"2011-04-09T20:00:00Z\"^^<http://www.w3.org/2001/XMLSchema#dateTime>)\n"
     ]
    }
   ],
   "source": [
    "conn.addData(event)\n",
    "showtriples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding an @id and @type to Objects\n",
    "\n",
    "In the above we see that the JSON-LD was correctly translated into triples but there are two immediate problems: first each subject is a blank node, the use of which is problematic when linking across repositories; and second, the object does not have an RDF type. We solve these problems by adding an `@id` to provide an IRI as the subject and adding a `@type` for the object (those are at the lines just after the @context definition):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\n",
    "  \"@context\": {\n",
    "      \"ical\": \"http://www.w3.org/2002/12/cal/ical#\",\n",
    "      \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "      \"ical:dtstart\": { \"@type\": \"xsd:dateTime\" }\n",
    "        },\n",
    "      \"@id\": \"ical:event-1\",\n",
    "      \"@type\": \"ical:Event\",\n",
    "      \"ical:summary\": \"Lady Gaga Concert\",\n",
    "      \"ical:location\": \"New Orleans Arena, New Orleans, Louisiana, USA\",\n",
    "      \"ical:dtstart\": \"2011-04-09T20:00:00Z\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a test function to test our JSON-LD objects. It is more powerful than needed right now (here we just need _conn_, _addData(event)_ and _showTriples()_ but **test** will be useful in most later examples. Note the _allow_external_references=True_ argument to _addData()_. Again, not needed in this example but later examples use external contexts and so this argument is required for those. Note that external references will not work on the free version of the cloud AllegroGraph servers. Please skip the next section if that is how you are connecting to a repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(object, json_ld_context=None, rdf_context=None, maxPrint=100, conn=conn):\n",
    "    conn.clear()\n",
    "    conn.addData(object, allow_external_references=True)\n",
    "    showtriples(limit=maxPrint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we apply test to event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<http://www.w3.org/2002/12/cal/ical#event-1>, <http://www.w3.org/2002/12/cal/ical#summary>, \"Lady Gaga Concert\")\n",
      "(<http://www.w3.org/2002/12/cal/ical#event-1>, <http://www.w3.org/2002/12/cal/ical#location>, \"New Orleans Arena, New Orleans, Louisiana, USA\")\n",
      "(<http://www.w3.org/2002/12/cal/ical#event-1>, <http://www.w3.org/2002/12/cal/ical#dtstart>, \"2011-04-09T20:00:00Z\"^^<http://www.w3.org/2001/XMLSchema#dateTime>)\n",
      "(<http://www.w3.org/2002/12/cal/ical#event-1>, <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>, <http://www.w3.org/2002/12/cal/ical#Event>)\n"
     ]
    }
   ],
   "source": [
    "test(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note in the above that we now have a proper subject and a type.\n",
    "\n",
    "## Referencing a External Context Via a URL\n",
    "\n",
    "The next object we add to AllegroGraph is a person object. This time the `@context` is not specified as a JSON object but as a link to a context that is stored at [http://schema.org/](http://schema.org/). Also in the definition of the function **test** above we had this parameter in `addData`: `allow_external_references=True`. Requiring that argument explicitly is a security feature. One should use external references only that context at that URL is trusted (as it is in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = {\n",
    "  \"@context\": \"http://schema.org/\",\n",
    "  \"@type\": \"Person\",\n",
    "  \"@id\": \"foaf:person-1\",\n",
    "  \"name\": \"Jane Doe\",\n",
    "  \"jobTitle\": \"Professor\",\n",
    "  \"telephone\": \"(425) 123-4567\",\n",
    "  \"url\": \"http://www.janedoe.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Performance by Adding Lists¶\n",
    "\n",
    "Adding one person at a time requires doing an interaction with the server for each person. It is much more efficient to add lists of objects all at once rather than one at a time. Note that `addData` will take a list of dicts and still do the right thing. So let us add a 1000 persons at the same time, each person being a copy of the above person but with a different `@id`. (The example code is repeated below for ease of copying.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [copy.deepcopy(person) for i in range(1000)]\n",
    "len(x)\n",
    "\n",
    "c = 0\n",
    "for el in x:\n",
    "    el['@id']= \"http://franz.com/person-\" + str(c)\n",
    "    c= c + 1\n",
    "\n",
    "test(x,maxPrint=10)\n",
    "\n",
    "conn.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Context Directly to an Object¶\n",
    "\n",
    "You can download a context directly in Python, modify it and then add it to the object you want to store. As an illustration we load a person context from json-ld.org (actually a fragment of the schema.org context) and insert it in a person object. (We have broken and truncated some output lines for clarity and all the code executed is repeated below for ease of copying.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=requests.get(\"https://json-ld.org/contexts/person.jsonld\").json()['@context']\n",
    "# The next produces lots of output, uncomment if desired\n",
    "#context\n",
    "\n",
    "person = {\n",
    "  \"@context\": context,\n",
    "  \"@type\": \"Person\",\n",
    "  \"@id\": \"foaf:person-1\",\n",
    "  \"name\": \"Jane Doe\",\n",
    "  \"jobTitle\": \"Professor\",\n",
    "  \"telephone\": \"(425) 123-4567\",\n",
    "}\n",
    "test(person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Graph of Objects\n",
    "\n",
    "We start by forcing a key’s value to be stored as a resource. We saw above that we could specify the value of a key to be a date using the `xsd:dateTime` specification. We now do it again for `foaf:birthdate`. Then we created several linked objects and show the connections using Gruff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = { \"foaf:child\": {\"@type\":\"@id\"},\n",
    "            \"foaf:brotherOf\": {\"@type\":\"@id\"},\n",
    "            \"foaf:birthdate\": {\"@type\":\"xsd:dateTime\"}}\n",
    "\n",
    "p1 = {\n",
    "    \"@context\": context,\n",
    "    \"@type\":\"foaf:Person\",\n",
    "    \"@id\":\"foaf:person-1\",\n",
    "    \"foaf:birthdate\": \"1958-04-09T20:00:00Z\",\n",
    "    \"foaf:child\": ['foaf:person-2', 'foaf:person-3']\n",
    "}\n",
    "\n",
    "p2 = {\n",
    "    \"@context\": context,\n",
    "    \"@type\":\"foaf:Person\",\n",
    "    \"@id\":\"foaf:person-2\",\n",
    "    \"foaf:brotherOf\": \"foaf:person-3\",\n",
    "    \"foaf:birthdate\": \"1992-04-09T20:00:00Z\",\n",
    "}\n",
    "\n",
    "p3 = {\"@context\": context,\n",
    "    \"@type\":\"foaf:Person\",\n",
    "    \"@id\":\"foaf:person-3\",\n",
    "    \"foaf:birthdate\": \"1994-04-09T20:00:00Z\",\n",
    "}\n",
    "\n",
    "test([p1,p2,p3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following shows the graph that we created in Gruff. Note that this is what JSON-LD is all about: connecting objects together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![person-graph.png](https://franz.com/agraph/support/documentation/current/python/_images/person-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON-LD Keyword Directives can be Added at any Level\n",
    "\n",
    "Here is an example from the wild. The URL [https://www.ulta.com/antioxidant-facial-oil?productId=xlsImpprod18731241](https://www.ulta.com/antioxidant-facial-oil?productId=xlsImpprod18731241) goes to a web page advertising a facial oil. (We make no claims or recommendations about this product. We are simply showing how JSON-LD appears in many places.) Look at the source of the page and you’ll find a JSON-LD object similar to the following. Note that @ directives go to any level. We added an _@id_ key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hippieoil = {\"@context\":\"http://schema.org\",\n",
    " \"@type\":\"Product\",\n",
    " \"@id\":\"http://franz.com/hippieoil\",\n",
    " \"aggregateRating\":\n",
    "    {\"@type\":\"AggregateRating\",\n",
    "     \"ratingValue\":4.6,\n",
    "     \"reviewCount\":73},\n",
    "     \"description\":\"\"\"Make peace with your inner hippie while hydrating & protecting against photoaging....Mad Hippie's preservative-free Antioxidant Facial Oil is truly the most natural way to moisturize.\"\"\",\n",
    "     \"brand\":\"Mad Hippie\",\n",
    "     \"name\":\"Antioxidant Facial Oil\",\n",
    "     \"image\":\"https://images.ulta.com/is/image/Ulta/2530018\",\n",
    "     \"productID\":\"2530018\",\n",
    "     \"offers\":\n",
    "        {\"@type\":\"Offer\",\n",
    "         \"availability\":\"http://schema.org/InStock\",\n",
    "         \"price\":\"24.99\",\n",
    "         \"priceCurrency\":\"USD\"}}\n",
    "\n",
    "\n",
    "test(hippieoil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hippie oil](https://franz.com/agraph/support/documentation/current/python/_images/hippieoil.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON-LD @graphs\n",
    "\n",
    "One can put one or more JSON-LD objects in an RDF named graph. This means that the fourth element of each triple generated from a JSON-LD object will have the specified graph name. Let’s show in an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {\n",
    "        \"name\": \"http://schema.org/name\",\n",
    "        \"description\": \"http://schema.org/description\",\n",
    "        \"image\": {\n",
    "            \"@id\": \"http://schema.org/image\", \"@type\": \"@id\" },\n",
    "        \"geo\": \"http://schema.org/geo\",\n",
    "        \"latitude\": {\n",
    "            \"@id\": \"http://schema.org/latitude\", \"@type\": \"xsd:float\" },\n",
    "        \"longitude\": {\n",
    "            \"@id\": \"http://schema.org/longitude\",  \"@type\": \"xsd:float\" },\n",
    "        \"xsd\": \"http://www.w3.org/2001/XMLSchema#\"\n",
    "    }\n",
    "\n",
    "place = {\n",
    "    \"@context\": context,\n",
    "    \"@id\": \"http://franz.com/place1\",\n",
    "    \"@graph\": {\n",
    "        \"@id\": \"http://franz.com/place1\",\n",
    "        \"@type\": \"http://franz.com/Place\",\n",
    "        \"name\": \"The Empire State Building\",\n",
    "        \"description\": \"The Empire State Building is a 102-story landmark in New York City.\",\n",
    "        \"image\": \"http://www.civil.usherbrooke.ca/cours/gci215a/empire-state-building.jpg\",\n",
    "        \"geo\": {\n",
    "               \"latitude\": \"40.75\",\n",
    "               \"longitude\": \"73.98\" }\n",
    "        }}\n",
    "\n",
    "test(place, maxPrint=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the fourth element (graph) of each of the triples is <http://franz.com/place1>. If you don’t add the @id the triples will be put in the default graph.\n",
    "\n",
    "Here a slightly more complex example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = {\n",
    "  \"@context\": {\n",
    "    \"dc\": \"http://purl.org/dc/elements/1.1/\",\n",
    "    \"ex\": \"http://example.org/vocab#\",\n",
    "    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "    \"ex:contains\": {\n",
    "      \"@type\": \"@id\"\n",
    "    }\n",
    "  },\n",
    "  \"@id\": \"http://franz.com/mygraph1\",\n",
    "  \"@graph\": [\n",
    "    {\n",
    "      \"@id\": \"http://example.org/library\",\n",
    "      \"@type\": \"ex:Library\",\n",
    "      \"ex:contains\": \"http://example.org/library/the-republic\"\n",
    "    },\n",
    "    {\n",
    "      \"@id\": \"http://example.org/library/the-republic\",\n",
    "      \"@type\": \"ex:Book\",\n",
    "      \"dc:creator\": \"Plato\",\n",
    "      \"dc:title\": \"The Republic\",\n",
    "      \"ex:contains\": \"http://example.org/library/the-republic#introduction\"\n",
    "    },\n",
    "    {\n",
    "      \"@id\": \"http://example.org/library/the-republic#introduction\",\n",
    "      \"@type\": \"ex:Chapter\",\n",
    "      \"dc:description\": \"An introductory chapter on The Republic.\",\n",
    "      \"dc:title\": \"The Introduction\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "test(library, maxPrint=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![library](https://franz.com/agraph/support/documentation/current/python/_images/library-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON-LD as a Document Store\n",
    "\n",
    "So far we have treated JSON-LD as a syntax to create triples. Now let us look at the way we can start using AllegroGraph as a combination of a document store and graph database at the same time. And also keep in mind that we want to do it in such a way that you as a Python developer can add documents such as dictionaries and also retrieve values or documents as dictionaries.\n",
    "\n",
    "## Setup\n",
    "\n",
    "The **Python source file jsonld_tutorial_helper.py** contains various definitions useful for the remainder of this example. Once it is downloaded, do the following (after adding the path to the filename):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn=createdb(\"docugraph\")\n",
    "from jsonld_tutorial_helper import *\n",
    "addNamespace(conn,\"jsonldmeta\",\"http://franz.com/ns/allegrograph/6.4/load-meta#\")\n",
    "addNamespace(conn,\"ical\",\"http://www.w3.org/2002/12/cal/ical#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use our event structure again and see how we can store this JSON document in the store as a document. Note that the `addData` call includes the keyword: `json_ld_store_source=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = {\n",
    "  \"@context\": {\n",
    "    \"@id\": \"ical:event1\",\n",
    "    \"@type\": \"ical:Event\",\n",
    "    \"ical\": \"http://www.w3.org/2002/12/cal/ical#\",\n",
    "    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",\n",
    "    \"ical:dtstart\": { \"@type\": \"xsd:dateTime\" }\n",
    "      },\n",
    "    \"ical:summary\": \"Lady Gaga Concert\",\n",
    "    \"ical:location\":\n",
    "    \"New Orleans Arena, New Orleans, Louisiana, USA\",\n",
    "    \"ical:dtstart\": \"2011-04-09T20:00:00Z\"\n",
    "}\n",
    "\n",
    "conn.addData(event, allow_external_references=True,json_ld_store_source=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _jsonld_tutorial_helper.py_ file defines the function store as simple wrapper around `addData` that always saves the JSON source. For experimentation reasons it also has a parameter `fresh` to clear out the repository first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonld_tutorial_helper import store\n",
    "\n",
    "store(conn,event, fresh=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the triples in Gruff we see that the JSON source is stored as well, on the root (top-level _@id_) of the JSON object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![event](https://franz.com/agraph/support/documentation/current/python/_images/event-store-source.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following part of the tutorial we want a little bit more data in our repository so please look at the helper file _jsonld_tutorial_helper.py_ where you will see that at the end we have a dictionary named obs with about 9 diverse objects, mostly borrowed from the json-ld.org site: a person, an event, a place, a recipe, a group of persons, a product, and our hippieoil.\n",
    "\n",
    "First let us store all the objects in a fresh repository. Then we check the size of the repo. Finally, we create a freetext index for the JSON sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store(conn,[v for k,v in obs.items()], fresh=True)\n",
    "print(conn.size())\n",
    "conn.createFreeTextIndex(\"source\",['<http://franz.com/ns/allegrograph/6.4/load-meta#source>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving values with SPARQL\n",
    "\n",
    "To simply retrieve values in objects but not the objects themselves, regular SPARQL queries will suffice. But because we want to make sure that Python developers only need to deal with regular Python structures as lists and dictionaries, we created a simple wrapper around SPARQL (see helper file). The name of the wrapper is `runSparql`.\n",
    "\n",
    "Here is an example. Let us find all the roots (top-level _@ids_) of objects and their types. Some objects do not have roots, so `None` stands for a blank node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(runSparql(conn,\"select ?s ?type { ?s a ?type }\"))\n",
    "[{'s': 'cocktail1', 'type': 'Cocktail'},\n",
    " {'s': None, 'type': 'Individual'},\n",
    " {'s': None, 'type': 'Vehicle'},\n",
    " {'s': 'tesla', 'type': 'Offering'},\n",
    " {'s': 'place1', 'type': 'Place'},\n",
    " {'s': None, 'type': 'Offer'},\n",
    " {'s': None, 'type': 'AggregateRating'},\n",
    " {'s': 'hippieoil', 'type': 'Product'},\n",
    " {'s': 'person-3', 'type': 'Person'},\n",
    " {'s': 'person-2', 'type': 'Person'},\n",
    " {'s': 'person-1', 'type': 'Person'},\n",
    " {'s': 'person-1000', 'type': 'Person'},\n",
    " {'s': 'event1', 'type': 'Event'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not see the full URIs for ?s and ?type. You can see them by adding an appropriate _format_ argument to **runSparql**, but the default is `terse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(runSparql(conn,\"select ?s ?type { ?s a ?type } limit 2\",format='ntriples'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving a Dictionary or Object\n",
    "\n",
    "`retrieve` is another function defined (in _jsonld_tutorial_helper.py_) for this tutorial. It is a wrapper around SPARQL to help extract objects. Here we see how we can use it. The sole purpose of `retrieve` is to retrieve the JSON-LD/dictionary based on a SPARQL pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve(conn,\"{?this a ical:Event}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, for a final fun (if you like expensive cars) example: Let us find a thing that is “fast and furious”, that is worth more than $80,000 and that we can pay for in cash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addNamespace(conn,\"gr\",\"http://purl.org/goodrelations/v1#\")\n",
    "\n",
    "x = retrieve(conn, \"\"\"{ ?this fti:match 'fast furious*';\n",
    "                          gr:acceptedPaymentMethods gr:Cash ;\n",
    "                          gr:hasPriceSpecification ?price .\n",
    "                    ?price gr:hasCurrencyValue ?value ;\n",
    "                           gr:hasCurrency \"USD\" .\n",
    "                    filter ( ?value > 80000.0 ) }\"\"\")\n",
    "\n",
    "pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0]['@id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 20: Reasoning\n",
    "\n",
    "AllegroGraph supports the following RDFS and OWL predicates:\n",
    "\n",
    "* `rdf:type`;\n",
    "* `rdfs:domain`;\n",
    "* `rdfs:range`;\n",
    "* `rdfs:subClassOf`;\n",
    "* `rdfs:subPropertyOf`;\n",
    "* `owl:inverseOf`;\n",
    "* `owl:sameAs`;\n",
    "* `owl:SymmetricProperty`;\n",
    "* `owl:TransitiveProperty`.\n",
    "\n",
    "A more detailed description of reasoning support can be found in the [Reasoner Tutorial](https://franz.com/agraph/support/documentation/current/reasoner-tutorial.html) chapter of AllegroGraph LISP documentation and is not repeated here for brevity. This tutorial only contains Python setup and querying examples.\n",
    "\n",
    "## Setup\n",
    "\n",
    "In order to enable reasoning, a connection to the server must be constructed by passing repository spec to a **reason()** function and creating a session from the resulting spec:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```conn = server.openSession(reason(repo))```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This connection must be used instead of a regular connection as an entry-point to execute queries on inferred statements. Here is a complete example of a setup that enables RDFS++ reasoning over a regular repository `repo`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.sail.allegrographserver import AllegroGraphServer\n",
    "from franz.openrdf.sail.spec import reason\n",
    "\n",
    "server = AllegroGraphServer()\n",
    "\n",
    "# Create repository 'repo' in the root catalog.\n",
    "server.openCatalog().createRepository('repo')\n",
    "\n",
    "# Open session with reasoning enabled on repository 'repo'.\n",
    "conn = server.openSession(reason('<repo>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoner examples\n",
    "\n",
    "The examples below assume that you already have an RDFS++ repository created as described in the Setup section. Each example removes all of the triples in the store, adds some new triples, and makes some queries to illustrate the different sorts of reasoning that AllegroGraph supports.\n",
    "\n",
    "In order to demonstrate the results, we will use the following function to print triples matching a simple pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptl(conn, s, p, o):\n",
    "    \"\"\"\n",
    "    Get statements matching subject, predicate and object,\n",
    "    which can be either entities represented by strings\n",
    "    of the form '<prefix>:<name>' or wildcard None values.\n",
    "    \"\"\"\n",
    "    namespaces = {\n",
    "        'rdf': conn.namespace('http://www.w3.org/1999/02/22-rdf-syntax-ns#'),\n",
    "        'ex': conn.namespace('ex://')\n",
    "    }\n",
    "\n",
    "    def part_to_uri(part):\n",
    "        # Split part string on ':' and get a full URI from a corresponding\n",
    "        # namespace object:\n",
    "        if part:\n",
    "            prefix, name = part.split(':', 2)\n",
    "            return getattr(namespaces[prefix], name)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    us, up, uo = (part_to_uri(part) for part in (s, p, o))\n",
    "    for rs, rp, ro, _ in conn.getStatements(us, up, uo):\n",
    "        print(\"{} {} {}.\".format(rs, rp, ro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to ask for inferred statements without creating a reasoning session by setting the value of the `includeInferred` argument to **getStatements()** to `True` as in the following example:\n",
    "```\n",
    "conn.getStatements(s, p, o, includeInferred=True)\n",
    "```\n",
    "\n",
    "### inverseOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "(28, \"Failed to connect to ag197y8xsj2epl2e.allegrograph.cloud port 44551 after 127323 ms: Couldn't connect to server\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m   @prefix owl: <http://www.w3.org/2002/07/owl#>.\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m   @prefix ex: <ex://>.\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m   ex:Jans    ex:owns       ex:Birra.\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m   ex:ownedBy owl:inverseOf ex:owns.\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m   ex:has     owl:inverseOf ex:ownedBy. \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/blade9/disk1/hans/miniconda3/envs/ag-notebook2/lib/python3.10/site-packages/franz/openrdf/repository/repositoryconnection.py:730\u001b[0m, in \u001b[0;36mRepositoryConnection.addData\u001b[0;34m(self, data, rdf_format, base_uri, context, attributes, json_ld_store_source, json_ld_context, allow_external_references, external_reference_timeout)\u001b[0m\n\u001b[1;32m    727\u001b[0m     rdf_format \u001b[38;5;241m=\u001b[39m RDFFormat\u001b[38;5;241m.\u001b[39mTURTLE\n\u001b[1;32m    729\u001b[0m ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_to_ntriples(context, none_is_mini_null\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_mini_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadData\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrdf_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson_ld_store_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_ld_store_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson_ld_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_ld_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_external_references\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_external_references\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexternal_reference_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexternal_reference_timeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/blade9/disk1/hans/miniconda3/envs/ag-notebook2/lib/python3.10/site-packages/franz/miniclient/repository.py:477\u001b[0m, in \u001b[0;36mRepository.loadData\u001b[0;34m(self, data, rdf_format, base_uri, context, commit_every, content_encoding, attributes, json_ld_store_source, json_ld_context, allow_external_references, external_reference_timeout)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloadData\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, rdf_format, base_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    473\u001b[0m              commit_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, content_encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attributes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    474\u001b[0m              json_ld_store_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    475\u001b[0m              json_ld_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allow_external_references\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    476\u001b[0m              external_reference_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 477\u001b[0m     \u001b[43mnullRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/statements?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43murlenc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbaseURI\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mattributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattributes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mencode_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mjsonLdStoreSource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_ld_store_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mjsonLdContext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_ld_context\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfix_json_ld_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_ld_context\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexternalReferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_external_references\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mextermalReferenceTimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexternal_reference_timeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFormat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmime_type_for_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrdf_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcontent_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/net/blade9/disk1/hans/miniconda3/envs/ag-notebook2/lib/python3.10/site-packages/franz/miniclient/request.py:125\u001b[0m, in \u001b[0;36mnullRequest\u001b[0;34m(obj, method, url, body, content_type, content_encoding)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     headers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Encoding: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m content_encoding]\n\u001b[0;32m--> 125\u001b[0m status, body \u001b[38;5;241m=\u001b[39m \u001b[43mmakeRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetHeaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m204\u001b[39m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestError(status, body)\n",
      "File \u001b[0;32m/net/blade9/disk1/hans/miniconda3/envs/ag-notebook2/lib/python3.10/site-packages/franz/miniclient/backends/curl.py:325\u001b[0m, in \u001b[0;36mmakeRequest\u001b[0;34m(obj, method, url, body, accept, contentType, callback, errCallback, headers)\u001b[0m\n\u001b[1;32m    323\u001b[0m buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[1;32m    324\u001b[0m curl\u001b[38;5;241m.\u001b[39msetopt(pycurl\u001b[38;5;241m.\u001b[39mWRITEFUNCTION, buf\u001b[38;5;241m.\u001b[39mwrite)\n\u001b[0;32m--> 325\u001b[0m \u001b[43mretrying_perform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m response \u001b[38;5;241m=\u001b[39m to_native_string(buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    327\u001b[0m buf\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/net/blade9/disk1/hans/miniconda3/envs/ag-notebook2/lib/python3.10/site-packages/franz/miniclient/backends/curl.py:169\u001b[0m, in \u001b[0;36mretrying_perform\u001b[0;34m(curl)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[43mcurl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pycurl\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;66;03m# Only retry in case of an ECONNRESET happening when\u001b[39;00m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;66;03m# the connection is created.\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: (28, \"Failed to connect to ag197y8xsj2epl2e.allegrograph.cloud port 44551 after 127323 ms: Couldn't connect to server\")"
     ]
    }
   ],
   "source": [
    "conn.addData(\"\"\"\n",
    "   @prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "   @prefix ex: <ex://>.\n",
    "\n",
    "   ex:Jans    ex:owns       ex:Birra.\n",
    "   ex:ownedBy owl:inverseOf ex:owns.\n",
    "   ex:has     owl:inverseOf ex:ownedBy. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Birra\", \"ex:ownedBy\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:ownedBy\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:ownedBy\", \"ex:Jans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"ex:has\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:has\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:has\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subPropertyOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "   @prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "   @prefix ex: <ex://>.\n",
    "   @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>.\n",
    "\n",
    "   ex:Jans   ex:hasPet          ex:Birra.\n",
    "   ex:Birra  ex:friendOf        ex:Samira.\n",
    "   ex:hasPet rdfs:subPropertyOf ex:owns. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"ex:owns\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"ex:owns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:owns\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"ex:hasPet\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"ex:hasPet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:hasPet\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverseOf with subPropertyOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct triples\n",
    "ptl(conn, \"ex:Jans\", \"ex:hasPet\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:hasPet\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"ex:hasPet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse of ex:hasPet\n",
    "ptl(conn, \"ex:Birra\", \"ex:petOf\", \"ex:Jans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:petOf\", \"ex:Jans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Birra\", \"ex:petOf\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subproperty\n",
    "ptl(conn, \"ex:Jans\", \"ex:owns\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"ex:owns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:owns\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse of subproperty\n",
    "ptl(conn, \"ex:Birra\", \"ex:ownedBy\", \"ex:Jans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:ownedBy\", \"ex:Jans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Birra\", \"ex:ownedBy\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse of inverse\n",
    "ptl(conn, \"ex:Jans\", \"ex:has\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:has\", \"ex:Birra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"ex:has\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sameAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "  @prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "  @prefix ex: <ex://>.\n",
    "  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>.\n",
    "\n",
    "  ex:Jans   ex:owns    ex:Birra.\n",
    "  ex:Jans   owl:sameAs ex:Jannes.\n",
    "  ex:Aasman owl:sameAs ex:Jannes.\n",
    "  ex:Birra  owl:sameAs ex:SonOfSamira.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Aasman\", \"ex:owns\", \"ex:SonOfSamira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Aasman\", \"ex:owns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:owns\", \"ex:SonOfSamira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:owns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sameAs with inverseOf and subPropertyOf¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "  @prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "  @prefix ex: <ex://>.\n",
    "  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>.\n",
    "\n",
    "  ex:Jans    ex:hasPet ex:Birra.\n",
    "  ex:ownedBy owl:inverseOf ex:owns.\n",
    "  ex:has     owl:inverseOf ex:ownedBy.\n",
    "  ex:hasPet  rdfs:subPropertyOf ex:owns.\n",
    "  ex:petOf   owl:inverseOf ex:hasPet.\n",
    "  ex:Birra   ex:age ex:twelve.\n",
    "\n",
    "  ex:Jans   owl:sameAs ex:Jannes.\n",
    "  ex:Aasman owl:sameAs ex:Jannes.\n",
    "  ex:Birra  owl:sameAs ex:SonOfSamira.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct triples\n",
    "ptl(conn, \"ex:Aasman\", \"ex:hasPet\", \"ex:SonOfSamira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:hasPet\", \"ex:SonOfSamira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Aasman\", \"ex:hasPet\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse of 'owns'\n",
    "ptl(conn, \"ex:SonOfSamira\", \"ex:petOf\", \"ex:Aasman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:petOf\", \"ex:Aasman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:SonOfSamira\", \"ex:petOf\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse of inverse\n",
    "ptl(conn, \"ex:Aasman\", \"ex:has\", \"ex:SonOfSamira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:has\", \"ex:SonOfSamira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Aasman\", \"ex:has\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subproperty\n",
    "ptl(conn, \"ex:Aasman\", \"ex:owns\", \"ex:SonOfSamira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Aasman\", \"ex:owns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:owns\", \"ex:SonOfSamira\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse of subproperty\n",
    "ptl(conn, \"ex:SonOfSamira\", \"ex:ownedBy\", \"ex:Aasman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:ownedBy\", \"ex:Aasman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:SonOfSamira\", \"ex:ownedBy\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type with subClassOf¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "  @prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "  @prefix ex: <ex://>.\n",
    "  @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>.\n",
    "  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>.\n",
    "\n",
    "  ex:Mammal rdfs:subClassOf ex:Animal.\n",
    "  ex:Human  rdfs:subClassOf ex:Mammal.\n",
    "  ex:Man    rdfs:subClassOf ex:Human.\n",
    "  ex:Jans   rdf:type        ex:Man.\n",
    "  ex:Jans   owl:sameAs      ex:Jannes.\n",
    "  ex:Aasman owl:sameAs      ex:Jannes.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"rdf:type\", \"ex:Man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"rdf:type\", \"ex:Human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"rdf:type\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Aasman\", \"rdf:type\", \"ex:Man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Aasman\", \"rdf:type\", \"ex:Human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Aasman\", \"rdf:type\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"rdf:type\", \"ex:Man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"rdf:type\", \"ex:Human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"rdf:type\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type with range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "  @prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "  @prefix ex: <ex://>.\n",
    "  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>.\n",
    "\n",
    "  ex:Jans   ex:hasPet      ex:Birra.\n",
    "  ex:hasPet rdfs:range      ex:Pet.\n",
    "  ex:Pet    rdfs:subClassOf ex:Mammal.\n",
    "  ex:Fatcat owl:sameAs      ex:Birra.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Birra\", \"rdf:type\", \"ex:Pet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Birra\", \"rdf:type\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"rdf:type\", \"ex:Pet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Birra\", \"rdf:type\", \"ex:Mammal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Fatcat\", \"rdf:type\", \"ex:Mammal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### type with domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "  @prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "  @prefix ex: <ex://>.\n",
    "  @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#>.\n",
    "\n",
    "  ex:Jans   ex:hasPet      ex:Birra.\n",
    "  ex:hasPet rdfs:domain     ex:Human.\n",
    "  ex:Human  rdfs:subClassOf ex:Mammal.\n",
    "  ex:Jans   owl:sameAs      ex:Aasman.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"rdf:type\", \"ex:Human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:Jans\", \"rdf:type\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"rdf:type\", \"ex:Human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"rdf:type\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitivity with sameAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.addData(\"\"\"\n",
    "  @prefix owl: <http://www.w3.org/2002/07/owl#>.\n",
    "  @prefix ex: <ex://>.\n",
    "  @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>.\n",
    "\n",
    "  ex:contains    rdf:type    owl:TransitiveProperty.\n",
    "  ex:USA         ex:contains ex:California.\n",
    "  ex:GoldenState ex:contains ex:ContraCosta.\n",
    "  ex:ContraCosta ex:contains ex:Moraga.\n",
    "\n",
    "  ex:USA        owl:sameAs ex:UncleSam.\n",
    "  ex:Moraga     owl:sameAs ex:MyTown.\n",
    "  ex:California owl:sameAs ex:GoldenState.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:USA\", \"ex:contains\", \"ex:Moraga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:UncleSam\", \"ex:contains\", \"ex:MyTown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:GoldenState\", \"ex:contains\", \"ex:Moraga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:California\", \"ex:contains\", \"ex:Moraga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:California\", \"ex:contains\", \"ex:MyTown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:USA\", \"ex:contains\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, \"ex:UncleSam\", \"ex:contains\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:contains\", \"ex:Moraga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptl(conn, None, \"ex:contains\", \"ex:MyTown\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ag-tutorial]",
   "language": "python",
   "name": "conda-env-ag-tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
